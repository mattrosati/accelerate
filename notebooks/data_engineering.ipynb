{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a913bb",
   "metadata": {},
   "source": [
    "# Exploring .icmh5 File Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525d6c2b",
   "metadata": {},
   "source": [
    "### Useful Imports and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd2aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")  # add project root\n",
    "\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data_utils import *\n",
    "\n",
    "# pending useful sklearn imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37997b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:10,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb17cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b937768",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(context=\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085b801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path constants\n",
    "data_dir = \"/home/mr2238/project_pi_np442/mr2238/accelerate/data\"\n",
    "img_dir = \"/home/mr2238/project_pi_np442/mr2238/accelerate/imgs/overview\"\n",
    "labels_path = os.path.join(data_dir, \"labels\")\n",
    "raw_data_path = os.path.join(data_dir, \"raw_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e12d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list files\n",
    "h5py_files = [f for f in os.listdir(raw_data_path) if f.endswith(\".icmh5\")]\n",
    "print(f\"Number of h5py files: {len(h5py_files)}\")\n",
    "print(f\"Example file: {h5py_files[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d077d9c6",
   "metadata": {},
   "source": [
    "### Summarize a random file\n",
    "\n",
    "Here we explore the structure and data series that compose one recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326dfc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load single random example\n",
    "idx = np.random.randint(0, len(h5py_files))\n",
    "example_file = h5py_files[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4075c785",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4fd98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract invalid value and numerics/waveforms\n",
    "with h5py.File(os.path.join(raw_data_path, example_file), \"r\") as f:\n",
    "    invalid_value = float(f.attrs[\"invalidValue\"][0])\n",
    "    print(f\"Invalid value: {invalid_value}\")\n",
    "    numerics = list(f[\"numerics\"].keys())\n",
    "    waves = list(f[\"waves\"].keys())\n",
    "    print(f\"Numerics: {numerics}\")\n",
    "    print(f\"Waves: {waves}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441d234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize random example file\n",
    "print(f\"Summarizing example file {example_file}:\")\n",
    "h5py_summarize(os.path.join(raw_data_path, example_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e03bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(os.path.join(raw_data_path, example_file), \"r\") as f:\n",
    "    print(pd.DataFrame(f[\"definitions/qualityRef\"][:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eff29cb",
   "metadata": {},
   "source": [
    "Now here we summarize the various data series to observe units and distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6b94a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize numerics and waveforms\n",
    "def summarize_series(name, obj, invalid_value=invalid_value):\n",
    "    print(f\"Dataset: {name}\")\n",
    "    df = pd.DataFrame(obj[:])\n",
    "    df.replace(invalid_value, np.nan, inplace=True)\n",
    "    print(f\"Number of missing values: {df.isna().sum().sum()}\")\n",
    "    print(df.describe())\n",
    "    print(\"\\n\")\n",
    "    return\n",
    "\n",
    "print(f\"Summarizing statistics for numerics and waveforms in file {example_file}:\")\n",
    "with h5py.File(os.path.join(raw_data_path, example_file), \"r\") as f:\n",
    "    f[\"numerics\"].visititems(summarize_series)\n",
    "    f[\"waves\"].visititems(summarize_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0adb72",
   "metadata": {},
   "source": [
    "### Plot a random file\n",
    "\n",
    "Here we plot the various data series of a random file to observe their dynamics. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f120278d",
   "metadata": {},
   "source": [
    "#### Timeseries data\n",
    "\n",
    "First we can just naively plot a data series without considering data gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ec374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(os.path.join(raw_data_path, example_file), \"r\") as f:\n",
    "    df = pd.DataFrame(f[\"numerics/hr\"])\n",
    "    df.replace(invalid_value, np.nan, inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.scatter(df.index/(60*60), df[0], label = \"Heart Rate\", s=0.5)\n",
    "ax.set_xlabel(\"Time (hr)\")\n",
    "ax.set_ylabel(\"Heart Rate (bpm)\")\n",
    "ax.set_title(\"Heart Rate over Time\")\n",
    "ax.set_ylim(25, 200)\n",
    "img_name = f\"hr_series_{example_file.removesuffix('.icmh5')}_nogaps.png\"\n",
    "plt.savefig(os.path.join(img_dir, img_name), bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd3e47d",
   "metadata": {},
   "source": [
    "However, there are gaps in this data, as seen in the ``index`` attribute of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c24867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot continuous time series with gaps as NaNs\n",
    "with h5py.File(os.path.join(raw_data_path, example_file), \"r\") as f:\n",
    "    df = build_continuous_time(f, 'numerics/hr')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.scatter(df.index/(60*60), df[0], label = \"Heart Rate\", s=0.5)\n",
    "ax.set_xlabel(\"Time (hr)\")\n",
    "ax.set_ylabel(\"Heart Rate (bpm)\")\n",
    "ax.set_title(\"Heart Rate over Time with recording gaps\")\n",
    "ax.set_ylim(25, 200)\n",
    "\n",
    "img_name = f\"hr_series_{example_file.removesuffix('.icmh5')}_full.png\"\n",
    "fig.savefig(os.path.join(img_dir, img_name), bbox_inches='tight')\n",
    "fig.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53f8399",
   "metadata": {},
   "source": [
    "#### Distribution of recording variables\n",
    "\n",
    "Next we can investigate the general distribution of all the variables of a random recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c460a03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can do histograms for all numerics\n",
    "with h5py.File(os.path.join(raw_data_path, example_file), \"r\") as f:\n",
    "    grp = f[\"numerics\"]\n",
    "    nrows = len(numerics)//2 + 1*(len(numerics)%2)\n",
    "    fig, axs = plt.subplots(nrows = 2, ncols = nrows, layout='constrained', figsize=(5* (len(numerics)//2 + 1), 8))\n",
    "    for i, n in enumerate(numerics):\n",
    "        df = pd.DataFrame(grp[n])\n",
    "        df.replace(invalid_value, np.nan, inplace=True)\n",
    "        ax = axs[i%2, i//2]\n",
    "        if n == \"t\":\n",
    "            ax.hist(df[0], bins=\"auto\", density=True, label=\"Distribution\")\n",
    "        else:\n",
    "            sns.kdeplot(df[0], ax=ax, fill=True, bw_adjust=3, label=\"Distribution\")\n",
    "        if n == \"spo2\":\n",
    "            ax.set_xlim(70, 110)\n",
    "        ax.set_ylabel(\"Density\")\n",
    "        ax.set_xlabel(\"Value\")\n",
    "        ax.set_title(n + f\" Distribution (Invalid Values = {df[0].isna().sum()/ len(df)*100:.3f}%)\")\n",
    "        mean_value = df[0].mean()\n",
    "        ax.axvline(x=mean_value, color='red', linestyle='--', label=f'Mean: {mean_value:.2f}')\n",
    "        ax.legend()\n",
    "    \n",
    "fig.suptitle(f\"Histogram of numeric values for file {example_file}\")\n",
    "img_name = f\"numerics_hist_{example_file.removesuffix('.icmh5')}.png\"\n",
    "plt.savefig(os.path.join(img_dir, img_name))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63ac274",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(waves)\n",
    "waves.remove(\"ecg.ii\") # it does not make sense to plot distribution of ECG voltages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82903f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can do histograms for all waves\n",
    "with h5py.File(os.path.join(raw_data_path, example_file), \"r\") as f:\n",
    "    grp = f[\"waves\"]\n",
    "    nrows = 4\n",
    "    ncols = len(waves)//nrows + 1*(len(waves)%nrows)\n",
    "    fig, axs = plt.subplots(nrows = nrows, ncols = ncols, layout='constrained', figsize=(8*ncols, 4*nrows))\n",
    "    for i, n in tqdm(enumerate(waves)):\n",
    "        df = pd.DataFrame(grp[n])\n",
    "        df.replace(invalid_value, np.nan, inplace=True)\n",
    "        ax = axs[i%nrows, i//nrows]\n",
    "        if n == \"cvp\" or n == \"pleth\" or n == \"icp\":\n",
    "            ax.hist(df[0], bins=\"auto\", density=True, label=\"Distribution\")\n",
    "        else:\n",
    "            sns.kdeplot(df[0], ax=ax, fill=True, bw_adjust=3, label=\"Distribution\")\n",
    "        if n == \"spo2\":\n",
    "            ax.set_xlim(70, 110)\n",
    "        ax.set_ylabel(\"Density\")\n",
    "        ax.set_xlabel(\"Value\")\n",
    "        ax.set_title(n + f\" Distribution (Invalid Values = {df[0].isna().sum()/ len(df)*100:.3f}%)\")\n",
    "        mean_value = df[0].mean()\n",
    "        ax.axvline(x=mean_value, color='red', linestyle='--', label=f'Mean: {mean_value:.2f}')\n",
    "        ax.legend()\n",
    "\n",
    "for i, a in enumerate(axs.flat):\n",
    "    if i > len(waves) - 1:\n",
    "        a.set_axis_off()\n",
    "\n",
    "fig.suptitle(f\"Histogram of waves values for file {example_file}\")\n",
    "img_name = f\"waves_hist_{example_file.removesuffix('.icmh5')}.png\"\n",
    "plt.savefig(os.path.join(img_dir, img_name))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1066a220",
   "metadata": {},
   "source": [
    "### Database-Wide Statistics\n",
    "\n",
    "In this section, we plot some database-wide statistics to obtain summaries of the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a87fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all the files and extract duration in seconds with gaps\n",
    "durations_gaps = {}\n",
    "\n",
    "for i, file in tqdm(enumerate(h5py_files)):\n",
    "    key = [s.split(\".\") for s in file.split(\"_\")][0][0]\n",
    "\n",
    "    with h5py.File(os.path.join(raw_data_path, file), \"r\") as f:\n",
    "        # duration with gaps\n",
    "        time = int(f.attrs[\"duration\"][0].replace(\" seconds\", \"\"))\n",
    "        durations_gaps[key] = time + durations_gaps.get(key, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2883add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all the files and extract duration in seconds without gaps\n",
    "durations_no_gaps = {}\n",
    "\n",
    "for i, file in tqdm(enumerate(h5py_files)):\n",
    "    key = [s.split(\".\") for s in file.split(\"_\")][0][0]\n",
    "\n",
    "    with h5py.File(os.path.join(raw_data_path, file), \"r\") as f:\n",
    "        # duration without gaps\n",
    "        try:\n",
    "            index = pd.DataFrame(f[\"numerics/hr\"].attrs[\"index\"])\n",
    "            time_per_segment = (index[\"length\"]).astype('float64')/index[\"frequency\"]\n",
    "            time = time_per_segment.sum().item()\n",
    "            durations_no_gaps[key] = time + durations_no_gaps.get(key, 0)\n",
    "        except:\n",
    "            print(f\"numerics/hr not found in {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b2c5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot violin plots of durations with and without gaps\n",
    "\n",
    "df1 = pd.DataFrame({'Value': np.array(list(durations_no_gaps.values()))/(60*60), 'Group': 'Excluding Gaps'})\n",
    "df2 = pd.DataFrame({'Value': np.array(list(durations_gaps.values()))/(60*60), 'Group': 'Including Gaps'})\n",
    "\n",
    "# Concatenate the two DataFrames\n",
    "combined_df = pd.concat([df1, df2])\n",
    "medians = combined_df.groupby(['Group'])['Value'].median()\n",
    "\n",
    "with plt.rc_context({'ytick.left': True}) and sns.axes_style(\"darkgrid\"):\n",
    "        fig, ax = plt.subplots(figsize=(12,6))\n",
    "        sns.violinplot(x='Group', y='Value', data=combined_df, ax=ax, hue=\"Group\", palette=\"pastel\")\n",
    "        ax.set_title('Side-by-Side Boxplots of Dataset Durations')\n",
    "        ax.set_ylabel('Duration (hours)')\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_yticks(np.arange(0, 251, 25), minor=True)\n",
    "        ax.set_ylim(0, 250)\n",
    "\n",
    "        for i, v in enumerate(medians):\n",
    "                ax.text((i+0.025), (v-2), str(round(v, 2)), fontsize = 12)\n",
    "\n",
    "        img_name = f\"duration_distributions.png\"\n",
    "        plt.savefig(os.path.join(img_dir, img_name), bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1556fb70",
   "metadata": {},
   "source": [
    "### Labels\n",
    "\n",
    "Now, let us explore the label dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4a5f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all patient ids for whom I have labels\n",
    "# ptid_list = set()\n",
    "# for i, file in enumerate(h5py_files):\n",
    "#     ptid = [s.split(\".\") for s in file.split(\"_\")][0][0]\n",
    "#     ptid_list.add(ptid)\n",
    "\n",
    "# ptid_list = list(ptid_list)\n",
    "ptid_list = list({fpath.split(\"_\")[0]: fpath for fpath in os.listdir(labels_path) if \".csv\" in fpath}.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3036a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random label file\n",
    "r_id = ptid_list[np.random.randint(0, len(ptid_list))]\n",
    "df = load_label(r_id, labels_path=labels_path, time=\"seconds\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0332a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df, find seconds elapsed to calculate opt MAP\n",
    "calc = 'MAPopt_Yale_affected_beta'\n",
    "elapsed_times = []\n",
    "for pt in tqdm(ptid_list):\n",
    "    t = find_time_elapsed(pt, calc, labels_path)\n",
    "    elapsed_times.append(t)\n",
    "\n",
    "print(pd.Series(elapsed_times).describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc29a5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context({'xtick.bottom': True}):\n",
    "    fig, ax = plt.subplots(figsize=(12,6))\n",
    "    sns.histplot(data=pd.Series(elapsed_times)/(60*60), ax=ax, kde=True, stat=\"density\", kde_kws={'bw_adjust': 0.4})\n",
    "    ax.set_title(\"Time required to calculate MAPopt\")\n",
    "    ax.set_xlabel('Time (hours)')\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.set_xticks(np.arange(0, 20, 0.5), minor=True)\n",
    "    ax.set_xlim(0, 20)\n",
    "\n",
    "    mean_value = (pd.Series(elapsed_times)/(60*60)).mean()\n",
    "    ax.axvline(x=mean_value, color='red', linestyle='--', label=f'Mean: {mean_value:.2f} hours')\n",
    "    ax.legend()\n",
    "\n",
    "    med_value = (pd.Series(elapsed_times)/(60*60)).median()\n",
    "    ax.axvline(x=med_value, color='green', linestyle='--', label=f'Median: {med_value:.2f} hours')\n",
    "    ax.legend()\n",
    "    \n",
    "\n",
    "\n",
    "    img_name = f\"mapopt_calc_distributions.png\"\n",
    "    plt.savefig(os.path.join(img_dir, img_name), bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5672642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
