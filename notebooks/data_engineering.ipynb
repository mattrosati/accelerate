{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a913bb",
   "metadata": {},
   "source": [
    "# Exploring .icmh5 File Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525d6c2b",
   "metadata": {},
   "source": [
    "### Useful Imports and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd2aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")  # add project root\n",
    "\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data_utils import *\n",
    "from src.constants import *\n",
    "\n",
    "# pending useful sklearn imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37997b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:10,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb17cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b937768",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(context=\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085b801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path constants\n",
    "data_dir = \"/home/mr2238/project_pi_np442/mr2238/accelerate/data\"\n",
    "img_dir = \"/home/mr2238/project_pi_np442/mr2238/accelerate/imgs/overview\"\n",
    "labels_path = os.path.join(data_dir, \"labels\")\n",
    "raw_data_path = os.path.join(data_dir, \"raw_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e12d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list files\n",
    "h5py_files = [f for f in os.listdir(raw_data_path) if f.endswith(\".icmh5\")]\n",
    "print(f\"Number of h5py files: {len(h5py_files)}\")\n",
    "print(f\"Example file: {h5py_files[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a57165",
   "metadata": {},
   "outputs": [],
   "source": [
    "'1006.icmh5' in h5py_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856acae2",
   "metadata": {},
   "source": [
    "### Analysis of Single Raw Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326dfc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load single random example\n",
    "idx = np.random.randint(0, len(h5py_files))\n",
    "example_file = h5py_files[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4075c785",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4fd98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract invalid value and numerics/waveforms\n",
    "with h5py.File(os.path.join(raw_data_path, example_file), \"r\") as f:\n",
    "    invalid_value = float(f.attrs[\"invalidValue\"][0])\n",
    "    print(f\"Invalid value: {invalid_value}\")\n",
    "    numerics = list(f[\"numerics\"].keys())\n",
    "    waves = list(f[\"waves\"].keys())\n",
    "    print(f\"Numerics: {numerics}\")\n",
    "    print(f\"Waves: {waves}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d077d9c6",
   "metadata": {},
   "source": [
    "#### Summarize a random file\n",
    "\n",
    "Here we explore the structure and data series that compose one recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441d234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize random example file\n",
    "print(f\"Summarizing example file {example_file}:\")\n",
    "h5py_summarize(os.path.join(raw_data_path, example_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e03bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(os.path.join(raw_data_path, example_file), \"r\") as f:\n",
    "    print(pd.DataFrame(f[\"definitions/qualityRef\"][:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eff29cb",
   "metadata": {},
   "source": [
    "Now here we summarize the various data series to observe units and distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6b94a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize numerics and waveforms\n",
    "def summarize_series(name, obj, invalid_value=invalid_value):\n",
    "    print(f\"Dataset: {name}\")\n",
    "    df = pd.DataFrame(obj[:])\n",
    "    df.replace(invalid_value, np.nan, inplace=True)\n",
    "    print(f\"Number of missing values: {df.isna().sum().sum()}\")\n",
    "    print(df.describe())\n",
    "    print(\"\\n\")\n",
    "    return\n",
    "\n",
    "print(f\"Summarizing statistics for numerics and waveforms in file {example_file}:\")\n",
    "with h5py.File(os.path.join(raw_data_path, example_file), \"r\") as f:\n",
    "    f[\"numerics\"].visititems(summarize_series)\n",
    "    f[\"waves\"].visititems(summarize_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0adb72",
   "metadata": {},
   "source": [
    "#### Plot a random file\n",
    "\n",
    "Here we plot the various data series of a random file to observe their dynamics. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f120278d",
   "metadata": {},
   "source": [
    "##### Timeseries data\n",
    "\n",
    "First we can just naively plot a data series without considering data gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ec374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(os.path.join(raw_data_path, example_file), \"r\") as f:\n",
    "    df = pd.DataFrame(f[\"numerics/hr\"])\n",
    "    df.replace(invalid_value, np.nan, inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.scatter(df.index/(60*60), df[0], label = \"Heart Rate\", s=0.5)\n",
    "ax.set_xlabel(\"Time (hr)\")\n",
    "ax.set_ylabel(\"Heart Rate (bpm)\")\n",
    "ax.set_title(\"Heart Rate over Time\")\n",
    "ax.set_ylim(25, 200)\n",
    "img_name = f\"hr_series_{example_file.removesuffix('.icmh5')}_nogaps.png\"\n",
    "plt.savefig(os.path.join(img_dir, img_name), bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd3e47d",
   "metadata": {},
   "source": [
    "However, there are gaps in this data, as seen in the ``index`` attribute of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c24867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot continuous time series with gaps as NaNs\n",
    "with h5py.File(os.path.join(raw_data_path, example_file), \"r\") as f:\n",
    "    df = build_continuous_time(f, 'numerics/hr')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.scatter(df.index/(60*60), df[0], label = \"Heart Rate\", s=0.5)\n",
    "ax.set_xlabel(\"Time (hr)\")\n",
    "ax.set_ylabel(\"Heart Rate (bpm)\")\n",
    "ax.set_title(\"Heart Rate over Time with recording gaps\")\n",
    "ax.set_ylim(25, 200)\n",
    "\n",
    "img_name = f\"hr_series_{example_file.removesuffix('.icmh5')}_full.png\"\n",
    "fig.savefig(os.path.join(img_dir, img_name), bbox_inches='tight')\n",
    "fig.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53f8399",
   "metadata": {},
   "source": [
    "##### Distribution of recording variables\n",
    "\n",
    "Next we can investigate the general distribution of all the variables of a random recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c460a03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can do histograms for all numerics\n",
    "with h5py.File(os.path.join(raw_data_path, example_file), \"r\") as f:\n",
    "    grp = f[\"numerics\"]\n",
    "    nrows = int(np.sqrt(len(numerics)))\n",
    "    ncols = len(numerics)//nrows + (len(numerics)%nrows)%nrows\n",
    "    fig, axs = plt.subplots(nrows = nrows, ncols = ncols, layout='constrained', figsize=(5* (len(numerics)//2 + 1), 8))\n",
    "    for i, n in enumerate(numerics):\n",
    "        df = pd.DataFrame(grp[n])\n",
    "        df.replace(invalid_value, np.nan, inplace=True)\n",
    "        ax = axs[i//ncols, i%ncols]\n",
    "        if n == \"t\":\n",
    "            ax.hist(df[0], bins=\"auto\", density=True, label=\"Distribution\")\n",
    "        else:\n",
    "            sns.kdeplot(df[0], ax=ax, fill=True, bw_adjust=3, label=\"Distribution\")\n",
    "        if n == \"spo2\":\n",
    "            ax.set_xlim(70, 110)\n",
    "        ax.set_ylabel(\"Density\")\n",
    "        ax.set_xlabel(\"Value\")\n",
    "        ax.set_title(n + f\" Distribution (Invalid Values = {df[0].isna().sum()/ len(df)*100:.3f}%)\")\n",
    "        mean_value = df[0].mean()\n",
    "        ax.axvline(x=mean_value, color='red', linestyle='--', label=f'Mean: {mean_value:.2f}')\n",
    "        ax.legend()\n",
    "    \n",
    "fig.suptitle(f\"Histogram of numeric values for file {example_file}\")\n",
    "img_name = f\"numerics_hist_{example_file.removesuffix('.icmh5')}.png\"\n",
    "plt.savefig(os.path.join(img_dir, img_name))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63ac274",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(waves)\n",
    "waves.remove(\"ecg.ii\") # it does not make sense to plot distribution of ECG voltages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82903f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can do histograms for all waves\n",
    "with h5py.File(os.path.join(raw_data_path, example_file), \"r\") as f:\n",
    "    grp = f[\"waves\"]\n",
    "    nrows = int(np.sqrt(len(waves)))\n",
    "    ncols = len(waves)//nrows + (len(waves)%nrows)%nrows\n",
    "    fig, axs = plt.subplots(nrows = nrows, ncols = ncols, layout='constrained', figsize=(8*ncols, 4*nrows))\n",
    "    for i, n in tqdm(enumerate(waves)):\n",
    "        df = pd.DataFrame(grp[n])\n",
    "        df.replace(invalid_value, np.nan, inplace=True)\n",
    "        ax = axs[i//ncols, i%ncols]\n",
    "        if n == \"cvp\" or n == \"pleth\" or n == \"icp\":\n",
    "            ax.hist(df[0], bins=\"auto\", density=True, label=\"Distribution\")\n",
    "        else:\n",
    "            sns.kdeplot(df[0], ax=ax, fill=True, bw_adjust=3, label=\"Distribution\")\n",
    "        if n == \"spo2\":\n",
    "            ax.set_xlim(70, 110)\n",
    "        ax.set_ylabel(\"Density\")\n",
    "        ax.set_xlabel(\"Value\")\n",
    "        ax.set_title(n + f\" Distribution (Invalid Values = {df[0].isna().sum()/ len(df)*100:.3f}%)\")\n",
    "        mean_value = df[0].mean()\n",
    "        ax.axvline(x=mean_value, color='red', linestyle='--', label=f'Mean: {mean_value:.2f}')\n",
    "        ax.legend()\n",
    "\n",
    "for i, a in enumerate(axs.flat):\n",
    "    if i > len(waves) - 1:\n",
    "        a.set_axis_off()\n",
    "\n",
    "fig.suptitle(f\"Histogram of waves values for file {example_file}\")\n",
    "img_name = f\"waves_hist_{example_file.removesuffix('.icmh5')}.png\"\n",
    "plt.savefig(os.path.join(img_dir, img_name))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1066a220",
   "metadata": {},
   "source": [
    "### Database-Wide Statistics\n",
    "\n",
    "In this section, we plot some database-wide statistics to obtain summaries of the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb6001f",
   "metadata": {},
   "source": [
    "#### Variables recorded per patient by count\n",
    "\n",
    "Not every patient has the same variables recorded. To select the best ones, we need some statistics on which proportion of patients have which variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6781cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e20153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find variables of patients\n",
    "recorded_vars = Counter()\n",
    "for i, file in tqdm(enumerate(h5py_files)):\n",
    "    with h5py.File(os.path.join(raw_data_path, file), \"r\") as f:\n",
    "        if invalid_value != float(f.attrs[\"invalidValue\"][0]):\n",
    "            print(\"Invalid value is different, problem\")\n",
    "            print(f\"Invalid value: {float(f.attrs['invalidValue'][0])}\")\n",
    "        \n",
    "        numerics = list(f[\"numerics\"].keys())\n",
    "        waves = list(f[\"waves\"].keys())\n",
    "        f_counter = Counter(numerics) + Counter(waves)\n",
    "        recorded_vars += f_counter\n",
    "\n",
    "vars_per_dataset = pd.Series(dict(recorded_vars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229b881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_per_dataset.sort_values(inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4d33b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context({'ytick.left': True, 'xtick.bottom': True}):\n",
    "    fig, ax = plt.subplots(figsize=(8,15))\n",
    "    \n",
    "    sns.barplot(data=vars_per_dataset / len(h5py_files) * 100, orient=\"h\", edgecolor=\"black\", width = 0.8, ax=ax)\n",
    "    \n",
    "    ax.set_title('Variables Recorded per Patient')\n",
    "    \n",
    "    ax.set_ylabel('Variable')\n",
    "    ax.tick_params(axis='y', labelsize=14)\n",
    "\n",
    "    ax.set_xlabel('Percentage of Patients with Recorded Data')\n",
    "    ax.set_xticks(np.arange(0, 101, 5), minor=True)\n",
    "    ax.set_xlim(0, 100)\n",
    "\n",
    "    img_name = f\"variable_coverage.png\"\n",
    "    plt.savefig(os.path.join(img_dir, img_name), bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9b5f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_per_dataset.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3dcc39",
   "metadata": {},
   "source": [
    "#### Durations with and without gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a87fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all the files and extract duration in seconds with gaps\n",
    "durations_gaps = {}\n",
    "\n",
    "for i, file in tqdm(enumerate(h5py_files)):\n",
    "    key = [s.split(\".\") for s in file.split(\"_\")][0][0]\n",
    "\n",
    "    with h5py.File(os.path.join(raw_data_path, file), \"r\") as f:\n",
    "        # duration with gaps\n",
    "        time = int(f.attrs[\"duration\"][0].replace(\" seconds\", \"\"))\n",
    "        durations_gaps[key] = time + durations_gaps.get(key, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2883add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all the files and extract duration in seconds without gaps\n",
    "durations_no_gaps = {}\n",
    "\n",
    "for i, file in tqdm(enumerate(h5py_files)):\n",
    "    key = [s.split(\".\") for s in file.split(\"_\")][0][0]\n",
    "\n",
    "    with h5py.File(os.path.join(raw_data_path, file), \"r\") as f:\n",
    "        # duration without gaps\n",
    "        try:\n",
    "            index = pd.DataFrame(f[\"numerics/hr\"].attrs[\"index\"])\n",
    "            time_per_segment = (index[\"length\"]).astype('float64')/index[\"frequency\"]\n",
    "            time = time_per_segment.sum().item()\n",
    "            durations_no_gaps[key] = time + durations_no_gaps.get(key, 0)\n",
    "        except:\n",
    "            print(f\"numerics/hr not found in {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b2c5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot violin plots of durations with and without gaps\n",
    "\n",
    "df1 = pd.DataFrame({'Value': np.array(list(durations_no_gaps.values()))/(60*60), 'Group': 'Excluding Gaps'})\n",
    "df2 = pd.DataFrame({'Value': np.array(list(durations_gaps.values()))/(60*60), 'Group': 'Including Gaps'})\n",
    "\n",
    "# Concatenate the two DataFrames\n",
    "combined_df = pd.concat([df1, df2])\n",
    "medians = combined_df.groupby(['Group'])['Value'].median()\n",
    "\n",
    "with plt.rc_context({'ytick.left': True}):\n",
    "        with sns.axes_style(\"darkgrid\"):\n",
    "                fig, ax = plt.subplots(figsize=(12,6))\n",
    "                sns.violinplot(x='Group', y='Value', data=combined_df, ax=ax, hue=\"Group\", palette=\"pastel\")\n",
    "                ax.set_title('Side-by-Side Violinplots of Dataset Durations')\n",
    "                ax.set_ylabel('Duration (hours)')\n",
    "                ax.set_xlabel('')\n",
    "                ax.set_yticks(np.arange(0, 251, 25), minor=True)\n",
    "                ax.set_ylim(0, 250)\n",
    "\n",
    "                for i, v in enumerate(medians):\n",
    "                        ax.text((i+0.025), (v-2), str(round(v, 2)), fontsize = 12)\n",
    "\n",
    "                img_name = f\"duration_distributions.png\"\n",
    "                plt.savefig(os.path.join(img_dir, img_name), bbox_inches='tight')\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4c5741",
   "metadata": {},
   "source": [
    "#### Global distributions of all raw variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf5aaba",
   "metadata": {},
   "source": [
    "We will drop the variables that are not recorded for >80% of patients, as that will only be a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5353c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9896b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = vars_per_dataset / len(h5py_files) > 0.80\n",
    "vars_per_dataset = vars_per_dataset[mask]\n",
    "print(vars_per_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16659b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_method = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b421ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_histograms(existing_hist, existing_edges, new_data, bins='auto'):\n",
    "    # If we don't yet have global bins, define them from new_data\n",
    "    if existing_edges is None:\n",
    "        hist, bin_edges = np.histogram(new_data, bins=bins)\n",
    "        return hist, bin_edges\n",
    "    \n",
    "    # Re-bin new_data to existing edges\n",
    "    hist, _ = np.histogram(new_data, bins=existing_edges)\n",
    "    existing_hist += hist\n",
    "    return existing_hist, existing_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4d496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_feature(feature, h5py_files, raw_data_path, bin_method, invalid_value, batch_size):\n",
    "    global_hist, global_edges = None, None\n",
    "    invalid_count = 0\n",
    "    length = 0\n",
    "    batch = []\n",
    "    for i, file in enumerate(h5py_files):\n",
    "        with h5py.File(os.path.join(raw_data_path, file), \"r\") as f:\n",
    "            for var_type in [\"waves\", \"numerics\"]:\n",
    "                if feature in f[f\"{var_type}\"].keys():\n",
    "                    var = var_type\n",
    "                    try:\n",
    "                        data = f[f\"{var_type}/{feature}\"][:]\n",
    "                        data[data == invalid_value] = np.nan\n",
    "                        valid = np.isfinite(data)\n",
    "                        length += data.shape[0]\n",
    "                        invalid_count += (~valid).sum()\n",
    "                        data = data[valid]\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "                    if len(batch) < batch_size:\n",
    "                        batch.append(data)\n",
    "                    else:\n",
    "                        merged = np.concatenate(batch)\n",
    "                        global_hist, global_edges = merge_histograms(global_hist, global_edges, merged, bins=bin_method)\n",
    "                        batch.clear()\n",
    "                else:\n",
    "                    continue\n",
    "    total_counts = global_hist.sum()\n",
    "    if total_counts == 0:\n",
    "        total_counts = 1\n",
    "    result_dict = {\"hist\": global_hist / total_counts, \"edges\":global_edges, \"var\": var, \"invalid_frac\": invalid_count / length}   \n",
    "    return feature, result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a4e088",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProcessPoolExecutor(max_workers=8) as ex:\n",
    "    results = list(tqdm(ex.map(partial(process_feature,\n",
    "                             h5py_files=h5py_files,\n",
    "                             raw_data_path=raw_data_path,\n",
    "                             bin_method=bin_method,\n",
    "                             invalid_value=invalid_value,\n",
    "                             batch_size=10),\n",
    "                     vars_per_dataset.index)))\n",
    "\n",
    "distributions = dict(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5d1f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(distributions[\"hr\"][\"invalid_frac\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a53bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = {f: distributions[f] for f in distributions.keys() if distributions[f][\"var\"] == 'numerics'}\n",
    "wave_features = {f: distributions[f] for f in distributions.keys() if distributions[f][\"var\"] == 'waves'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ea25da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can do histograms for all numerics\n",
    "numerics = list(numeric_features.keys())\n",
    "waves = list(wave_features.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce94a918",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = int(np.sqrt(len(numerics)))\n",
    "ncols = len(numerics)//nrows + (len(numerics)%nrows)%nrows\n",
    "fig, axs = plt.subplots(nrows = nrows, ncols = ncols, layout='constrained', figsize=(5* (len(numerics)//2 + 1), 8))\n",
    "for i, n in enumerate(numerics):\n",
    "    edges = distributions[n][\"edges\"]\n",
    "    hist = distributions[n][\"hist\"]\n",
    "    ax = axs[i//ncols, i%ncols]\n",
    "    sns.barplot(x=edges[:-1], y=hist, ax=ax, native_scale=True, edgecolor=\"black\", width=1)\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.set_xlabel(\"Value\")\n",
    "    ax.set_title(n + f\" Distribution (Invalid Values = {distributions[n]['invalid_frac'].item() * 100:.3f}%)\")\n",
    "    mean_value = (hist * edges[:-1]).sum()\n",
    "    ax.axvline(x=mean_value, color='red', linestyle='--', label=f'Approximate Mean: {mean_value:.2f}')\n",
    "    ax.legend()\n",
    "    \n",
    "fig.suptitle(f\"Histogram of numeric values\")\n",
    "img_name = f\"numerics_hist_alldata.png\"\n",
    "plt.savefig(os.path.join(img_dir, img_name))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fec191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can do histograms for all waves\n",
    "nrows = int(np.sqrt(len(waves)))\n",
    "ncols = len(waves)//nrows + (len(waves)%nrows)%nrows\n",
    "fig, axs = plt.subplots(nrows = nrows, ncols = ncols, layout='constrained', figsize=(8*ncols, 4*nrows))\n",
    "for i, n in enumerate(waves):\n",
    "    edges = distributions[n][\"edges\"]\n",
    "    hist = distributions[n][\"hist\"]\n",
    "    ax = axs[i//ncols, i%ncols]\n",
    "    sns.barplot(x=edges[:-1], y=hist, ax=ax, native_scale=True, edgecolor=\"black\", width=1)\n",
    "    # if n == \"cvp\" or n == \"pleth\" or n == \"icp\":\n",
    "    #     ax.hist(df[0], bins=\"auto\", density=True, label=\"Distribution\")\n",
    "    # else:\n",
    "    #     sns.kdeplot(df[0], ax=ax, fill=True, bw_adjust=3, label=\"Distribution\")\n",
    "    # if n == \"spo2\":\n",
    "    #     ax.set_xlim(70, 110)\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.set_xlabel(\"Value\")\n",
    "    ax.set_title(n + f\" Distribution (Invalid Values = {distributions[n]['invalid_frac'].item() * 100:.3f}%)\")\n",
    "    mean_value = (hist * edges[:-1]).sum()\n",
    "    ax.axvline(x=mean_value, color='red', linestyle='--', label=f'Approximate Mean: {mean_value:.2f}')\n",
    "    ax.legend()\n",
    "\n",
    "for i, a in enumerate(axs.flat):\n",
    "    if i > len(waves) - 1:\n",
    "        a.set_axis_off()\n",
    "\n",
    "fig.suptitle(f\"Histogram of waveform data\")\n",
    "img_name = f\"waves_hist_alldata.png\"\n",
    "# plt.savefig(os.path.join(img_dir, img_name))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1556fb70",
   "metadata": {},
   "source": [
    "### Labels\n",
    "\n",
    "Now, let us explore the label dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4a5f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptid_raw_list = [fpath.split(\".\")[0] for fpath in os.listdir(raw_data_path) if fpath.endswith(\".icmh5\")]\n",
    "\n",
    "# remove patients for which no labels\n",
    "ptid_list = [f for f in ptid_raw_list if f.split(\"_\")[0] + \"_updated.csv\" in os.listdir(labels_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3036a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random label file\n",
    "r_id = ptid_list[np.random.randint(0, len(ptid_list))]\n",
    "df = load_label(r_id, labels_path=labels_path, time=\"s\")\n",
    "print(r_id)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0332a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df, find seconds elapsed to calculate opt MAP\n",
    "calc = TARGETS\n",
    "start_times = {fpath.split(\".\")[0] : h5py.File(os.path.join(raw_data_path, fpath), \"r\").attrs[\"dataStartTimeUnix\"][0] for fpath in os.listdir(raw_data_path) if fpath.split(\".\")[0]in ptid_list}\n",
    "elapsed_times = pd.Series([find_time_elapsed(pt, calc, labels_path, start_time=int(start_times[pt]), time='s') for pt in tqdm(ptid_list)]).dropna()\n",
    "print(elapsed_times.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc6378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(start_times[\"690_1\"], start_times[\"690_2\"], start_times[\"690_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cbbfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_times = elapsed_times[elapsed_times > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3d9226",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_data = elapsed_times.shape[0]\n",
    "all_pt = len(ptid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d65fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(elapsed_times.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc29a5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context({'xtick.bottom': True, 'ytick.left': True}):\n",
    "    fig, ax = plt.subplots(figsize=(12,6))\n",
    "    sns.histplot(data=pd.Series(elapsed_times)/(60*60), ax=ax, kde=True, stat=\"probability\", kde_kws={'bw_adjust': 0.4})\n",
    "    ax.set_title(f\"Time required to calculate limits of autoregulation (calculated for {with_data}/{all_pt} patients)\")\n",
    "    ax.set_xlabel('Time (hours)')\n",
    "    ax.set_ylabel(\"Fraction of Patients\")\n",
    "    ax.set_xticks(np.arange(0, 20, 0.5), minor=True)\n",
    "    ax.set_xlim(0, 20)\n",
    "\n",
    "    mean_value = (pd.Series(elapsed_times)/(60*60)).mean()\n",
    "    ax.axvline(x=mean_value, color='red', linestyle='--', label=f'Mean: {mean_value:.2f} hours')\n",
    "    ax.legend()\n",
    "\n",
    "    med_value = (pd.Series(elapsed_times)/(60*60)).median()\n",
    "    ax.axvline(x=med_value, color='green', linestyle='--', label=f'Median: {med_value:.2f} hours')\n",
    "    ax.legend()\n",
    "    \n",
    "\n",
    "\n",
    "    img_name = f\"mapopt_calc_distributions.png\"\n",
    "    plt.savefig(os.path.join(img_dir, img_name), bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5672642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
