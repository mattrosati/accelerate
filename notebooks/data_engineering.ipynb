{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a913bb",
   "metadata": {},
   "source": [
    "# Exploring .icmh5 File Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525d6c2b",
   "metadata": {},
   "source": [
    "### Useful Imports and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddd2aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")  # add project root\n",
    "\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data_utils import *\n",
    "from src.constants import *\n",
    "\n",
    "# pending useful sklearn imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37997b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:10,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cb17cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b937768",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(context=\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "085b801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path constants\n",
    "data_dir = \"/home/mr2238/project_pi_np442/mr2238/accelerate/data\"\n",
    "img_dir = \"/home/mr2238/project_pi_np442/mr2238/accelerate/imgs/overview\"\n",
    "labels_path = os.path.join(data_dir, \"labels\")\n",
    "raw_data_path = os.path.join(data_dir, \"raw_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10e12d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of h5py files: 215\n",
      "Example file: 1002.icmh5\n"
     ]
    }
   ],
   "source": [
    "# list files\n",
    "h5py_files = [f for f in os.listdir(raw_data_path) if f.endswith(\".icmh5\")]\n",
    "print(f\"Number of h5py files: {len(h5py_files)}\")\n",
    "print(f\"Example file: {h5py_files[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42a57165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'1006.icmh5' in h5py_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856acae2",
   "metadata": {},
   "source": [
    "### Analysis of Single Raw Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "326dfc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load single random example\n",
    "idx = np.random.randint(0, len(h5py_files))\n",
    "example_file = h5py_files[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4075c785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657.icmh5\n"
     ]
    }
   ],
   "source": [
    "print(example_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e4fd98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid value: -99999.0\n",
      "Numerics: ['hr', 'rr', 'rso2l', 'rso2r', 'spo2', 't']\n",
      "Waves: ['abp', 'cvp', 'deoxhg_l', 'deoxhg_r', 'ecg.ii', 'icp', 'oxhg_l', 'oxhg_r', 'pleth', 'scthg_l', 'scthg_r', 'sthg_index_l', 'sthg_index_r']\n"
     ]
    }
   ],
   "source": [
    "# extract invalid value and numerics/waveforms\n",
    "with h5py.File(os.path.join(raw_data_path, example_file), \"r\") as f:\n",
    "    invalid_value = float(f.attrs[\"invalidValue\"][0])\n",
    "    print(f\"Invalid value: {invalid_value}\")\n",
    "    numerics = list(f[\"numerics\"].keys())\n",
    "    waves = list(f[\"waves\"].keys())\n",
    "    print(f\"Numerics: {numerics}\")\n",
    "    print(f\"Waves: {waves}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d077d9c6",
   "metadata": {},
   "source": [
    "#### Summarize a random file\n",
    "\n",
    "Here we explore the structure and data series that compose one recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "441d234b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing example file 657.icmh5:\n",
      "Summarizing file /home/mr2238/project_pi_np442/mr2238/accelerate/data/raw_data/657.icmh5:\n",
      "Global attributes:\n",
      "dataCollectionSoftware: ['']\n",
      "dataEndTime: ['2018/11/14 09:25:48']\n",
      "dataEndTimeUnix: ['1542187548']\n",
      "dataProcessingSoftware: ['ICM+ 9.3.1.1']\n",
      "dataStartTime: ['2018/11/12 15:37:30']\n",
      "dataStartTimeUnix: ['1542037050']\n",
      "dateTimeFormat: ['yyyy/mm/dd hh:nn:ss']\n",
      "duration: ['150498 seconds']\n",
      "formatVersion: ['1.3']\n",
      "invalidValue: ['-99999']\n",
      "protocol: ['Generic']\n",
      "\n",
      "Contents:\n",
      "Group: aux\n",
      "Group: aux/ICM+\n",
      "Dataset: aux/ICM+/DTAFilesLog, shape: (140,), dtype: object\n",
      "Group: definitions\n",
      "Dataset: definitions/indexStruct, shape: (4,), dtype: [('field', 'O'), ('description', 'O')]\n",
      "Attributes:\n",
      "CLASS: b'TABLE'\n",
      "FIELD_0_NAME: b'field'\n",
      "FIELD_1_NAME: b'description'\n",
      "TITLE: b'indexStruct'\n",
      "VERSION: b'3.0'\n",
      "description: [\"Description of the 'index' dataset/attribute format\"]\n",
      "Dataset: definitions/qualityRef, shape: (25,), dtype: [('indicator', '<u4'), ('description', 'O')]\n",
      "Attributes:\n",
      "CLASS: b'TABLE'\n",
      "FIELD_0_NAME: b'indicator'\n",
      "FIELD_1_NAME: b'description'\n",
      "TITLE: b'qualityRef'\n",
      "VERSION: b'3.0'\n",
      "description: ['This is a dictionary of Quality indicators. The data quality value is a bit set (sum) of these.']\n",
      "Dataset: definitions/qualityStruct, shape: (2,), dtype: [('field', 'O'), ('description', 'O')]\n",
      "Attributes:\n",
      "CLASS: b'TABLE'\n",
      "FIELD_0_NAME: b'field'\n",
      "FIELD_1_NAME: b'description'\n",
      "TITLE: b'qualityStruct'\n",
      "VERSION: b'3.0'\n",
      "description: [\"Description of the 'quality' dataset/attribute format\"]\n",
      "Dataset: global.quality, shape: (1,), dtype: [('time', '<u8'), ('value', '<u4')]\n",
      "Group: numerics\n",
      "Dataset: numerics/hr, shape: (142886,), dtype: float32\n",
      "Attributes:\n",
      "index:\n",
      "   startidx         starttime  length  frequency\n",
      "0         0  1542037050315000      50       1.00\n",
      "1        50  1542037140620000   17200       1.00\n",
      "2     17250  1542058987770000    5055       1.00\n",
      "3     22305  1542064067940000    2096       1.00\n",
      "4     24401  1542066174300000   40736       1.00\n",
      "5     65137  1542108684290000      80       1.00\n",
      "6     65217  1542109872760000   77669       1.00\n",
      "location: ['']\n",
      "metric: ['']\n",
      "modality: ['hr']\n",
      "quality:\n",
      "               time  value\n",
      "0  1542037050315000      0\n",
      "source: ['Intellivue']\n",
      "units: ['']\n",
      "Dataset: numerics/rr, shape: (142886,), dtype: float32\n",
      "Attributes:\n",
      "index:\n",
      "   startidx         starttime  length  frequency\n",
      "0         0  1542037050315000      50       1.00\n",
      "1        50  1542037140620000   17200       1.00\n",
      "2     17250  1542058987770000    5055       1.00\n",
      "3     22305  1542064067940000    2096       1.00\n",
      "4     24401  1542066174300000   40736       1.00\n",
      "5     65137  1542108684290000      80       1.00\n",
      "6     65217  1542109872760000   77669       1.00\n",
      "location: ['']\n",
      "metric: ['']\n",
      "modality: ['rr']\n",
      "quality:\n",
      "               time  value\n",
      "0  1542037050315000      0\n",
      "source: ['Intellivue']\n",
      "units: ['']\n",
      "Dataset: numerics/rso2l, shape: (147100,), dtype: float32\n",
      "Attributes:\n",
      "index:\n",
      "   startidx         starttime  length  frequency\n",
      "0         0  1542037140620000   17200       1.00\n",
      "1     17200  1542054356040000    4620       1.00\n",
      "2     21820  1542058987770000    5055       1.00\n",
      "3     26875  1542066174300000   40736       1.00\n",
      "4     67611  1542106931080000    1740       1.00\n",
      "5     69351  1542108684290000      80       1.00\n",
      "6     69431  1542109872760000   77669       1.00\n",
      "location: ['']\n",
      "metric: ['']\n",
      "modality: ['rso2l']\n",
      "quality:\n",
      "                time  value\n",
      "0   1542037140620000      0\n",
      "1   1542048655216000  32768\n",
      "2   1542048655883000      0\n",
      "3   1542048798495000  32768\n",
      "4   1542048798841000      0\n",
      "..               ...    ...\n",
      "80  1542166865556000      0\n",
      "81  1542180573379000  32768\n",
      "82  1542180595842000      0\n",
      "83  1542183042309000  32768\n",
      "84  1542183056194000      0\n",
      "\n",
      "[85 rows x 2 columns]\n",
      "source: ['Intellivue']\n",
      "units: ['%']\n",
      "Dataset: numerics/rso2r, shape: (147100,), dtype: float32\n",
      "Attributes:\n",
      "index:\n",
      "   startidx         starttime  length  frequency\n",
      "0         0  1542037140620000   17200       1.00\n",
      "1     17200  1542054356040000    4620       1.00\n",
      "2     21820  1542058987770000    5055       1.00\n",
      "3     26875  1542066174300000   40736       1.00\n",
      "4     67611  1542106931080000    1740       1.00\n",
      "5     69351  1542108684290000      80       1.00\n",
      "6     69431  1542109872760000   77669       1.00\n",
      "location: ['']\n",
      "metric: ['']\n",
      "modality: ['rso2r']\n",
      "quality:\n",
      "               time  value\n",
      "0  1542037140620000      0\n",
      "source: ['Intellivue']\n",
      "units: ['%']\n",
      "Dataset: numerics/spo2, shape: (142886,), dtype: float32\n",
      "Attributes:\n",
      "index:\n",
      "   startidx         starttime  length  frequency\n",
      "0         0  1542037050315000      50       1.00\n",
      "1        50  1542037140620000   17200       1.00\n",
      "2     17250  1542058987770000    5055       1.00\n",
      "3     22305  1542064067940000    2096       1.00\n",
      "4     24401  1542066174300000   40736       1.00\n",
      "5     65137  1542108684290000      80       1.00\n",
      "6     65217  1542109872760000   77669       1.00\n",
      "location: ['']\n",
      "metric: ['']\n",
      "modality: ['spo2']\n",
      "quality:\n",
      "               time  value\n",
      "0  1542037050315000      0\n",
      "source: ['Intellivue']\n",
      "units: ['%']\n",
      "Dataset: numerics/t, shape: (142886,), dtype: float32\n",
      "Attributes:\n",
      "index:\n",
      "   startidx         starttime  length  frequency\n",
      "0         0  1542037050315000      50       1.00\n",
      "1        50  1542037140620000   17200       1.00\n",
      "2     17250  1542058987770000    5055       1.00\n",
      "3     22305  1542064067940000    2096       1.00\n",
      "4     24401  1542066174300000   40736       1.00\n",
      "5     65137  1542108684290000      80       1.00\n",
      "6     65217  1542109872760000   77669       1.00\n",
      "location: ['']\n",
      "metric: ['']\n",
      "modality: ['t']\n",
      "quality:\n",
      "               time  value\n",
      "0  1542037050315000      0\n",
      "source: ['Intellivue']\n",
      "units: ['']\n",
      "Dataset: packaging.log, shape: (19,), dtype: object\n",
      "Group: waves\n",
      "Dataset: waves/abp, shape: (17861333,), dtype: float32\n",
      "Attributes:\n",
      "index:\n",
      "   startidx         starttime   length  frequency\n",
      "0         0  1542037050315000     6249     125.00\n",
      "1      6249  1542037140620000  2150000     125.00\n",
      "2   2156249  1542058987770000   631875     125.00\n",
      "3   2788124  1542064067940000   261876     125.00\n",
      "4   3050000  1542066174300000  5091882     125.00\n",
      "5   8141882  1542108684290000     9965     125.00\n",
      "6   8151847  1542109872760000  9709486     125.00\n",
      "location: ['']\n",
      "metric: ['']\n",
      "modality: ['abp']\n",
      "quality:\n",
      "                time  value\n",
      "0   1542037050315000      0\n",
      "1   1542038098951000  32768\n",
      "2   1542038099348000      0\n",
      "3   1542038109875000  32768\n",
      "4   1542038110227000      0\n",
      "..               ...    ...\n",
      "72  1542111129480000      0\n",
      "73  1542130576377000  32768\n",
      "74  1542130577825000      0\n",
      "75  1542130687597000  32768\n",
      "76  1542130695517000      0\n",
      "\n",
      "[77 rows x 2 columns]\n",
      "source: ['Intellivue']\n",
      "units: ['']\n",
      "Dataset: waves/cvp, shape: (17861333,), dtype: float32\n",
      "Attributes:\n",
      "index:\n",
      "   startidx         starttime   length  frequency\n",
      "0         0  1542037050315000     6249     125.00\n",
      "1      6249  1542037140620000  2150000     125.00\n",
      "2   2156249  1542058987770000   631875     125.00\n",
      "3   2788124  1542064067940000   261876     125.00\n",
      "4   3050000  1542066174300000  5091882     125.00\n",
      "5   8141882  1542108684290000     9965     125.00\n",
      "6   8151847  1542109872760000  9709486     125.00\n",
      "location: ['']\n",
      "metric: ['']\n",
      "modality: ['cvp']\n",
      "quality:\n",
      "               time  value\n",
      "0  1542037050315000      0\n",
      "source: ['Intellivue']\n",
      "units: ['']\n",
      "Dataset: waves/deoxhg_l, shape: (18388184,), dtype: float32\n",
      "Attributes:\n",
      "index:\n",
      "   startidx         starttime   length  frequency\n",
      "0         0  1542037140620000  2150000     125.00\n",
      "1   2150000  1542054356040000   577500     125.00\n",
      "2   2727500  1542058987770000   631875     125.00\n",
      "3   3359375  1542066174300000  5091882     125.00\n",
      "4   8451257  1542106931080000   217500     125.00\n",
      "5   8668757  1542108684290000     9965     125.00\n",
      "6   8678722  1542109872760000  9709462     125.00\n",
      "location: ['']\n",
      "metric: ['']\n",
      "modality: ['deoxhg_l']\n",
      "quality:\n",
      "               time  value\n",
      "0  1542037140620000      0\n",
      "source: ['Intellivue']\n",
      "units: ['']\n",
      "Dataset: waves/deoxhg_r, shape: (18388184,), dtype: float32\n",
      "Attributes:\n",
      "index:\n",
      "   startidx         starttime   length  frequency\n",
      "0         0  1542037140620000  2150000     125.00\n",
      "1   2150000  1542054356040000   577500     125.00\n",
      "2   2727500  1542058987770000   631875     125.00\n",
      "3   3359375  1542066174300000  5091882     125.00\n",
      "4   8451257  1542106931080000   217500     125.00\n",
      "5   8668757  1542108684290000     9965     125.00\n",
      "6   8678722  1542109872760000  9709462     125.00\n",
      "location: ['']\n",
      "metric: ['']\n",
      "modality: ['deoxhg_r']\n",
      "quality:\n",
      "               time  value\n",
      "0  1542037140620000      0\n",
      "source: ['Intellivue']\n",
      "units: ['']\n",
      "Dataset: waves/ecg.ii, shape: (71445343,), dtype: float32\n",
      "Attributes:\n",
      "index:\n",
      "   startidx         starttime    length  frequency\n",
      "0         0  1542037050315000     24995     500.00\n",
      "1     24995  1542037140620000   8599997     500.00\n",
      "2   8624992  1542058987770000   2527497     500.00\n",
      "3  11152489  1542064067940000   1047503     500.00\n",
      "4  12199992  1542066174300000  20367527     500.00\n",
      "5  32567519  1542108684290000     39859     500.00\n",
      "6  32607378  1542109872760000  38837965     500.00\n",
      "location: ['']\n",
      "metric: ['']\n",
      "modality: ['ecg.ii']\n",
      "quality:\n",
      "               time  value\n",
      "0  1542037050315000      0\n",
      "source: ['Intellivue']\n",
      "units: ['']\n",
      "Dataset: waves/icp, shape: (17861333,), dtype: float32\n",
      "Attributes:\n",
      "index:\n",
      "   startidx         starttime   length  frequency\n",
      "0         0  1542037050315000     6249     125.00\n",
      "1      6249  1542037140620000  2150000     125.00\n",
      "2   2156249  1542058987770000   631875     125.00\n",
      "3   2788124  1542064067940000   261876     125.00\n",
      "4   3050000  1542066174300000  5091882     125.00\n",
      "5   8141882  1542108684290000     9965     125.00\n",
      "6   8151847  1542109872760000  9709486     125.00\n",
      "location: ['']\n",
      "metric: ['']\n",
      "modality: ['icp']\n",
      "quality:\n",
      "               time  value\n",
      "0  1542037050315000      0\n",
      "source: ['Intellivue']\n",
      "units: ['']\n",
      "Dataset: waves/oxhg_l, shape: (18388184,), dtype: float32\n",
      "Attributes:\n",
      "index:\n",
      "   startidx         starttime   length  frequency\n",
      "0         0  1542037140620000  2150000     125.00\n",
      "1   2150000  1542054356040000   577500     125.00\n",
      "2   2727500  1542058987770000   631875     125.00\n",
      "3   3359375  1542066174300000  5091882     125.00\n",
      "4   8451257  1542106931080000   217500     125.00\n",
      "5   8668757  1542108684290000     9965     125.00\n",
      "6   8678722  1542109872760000  9709462     125.00\n",
      "location: ['']\n",
      "metric: ['']\n",
      "modality: ['oxhg_l']\n",
      "quality:\n",
      "               time  value\n",
      "0  1542037140620000      0\n",
      "source: ['Intellivue']\n",
      "units: ['']\n",
      "Dataset: waves/oxhg_r, shape: (18388184,), dtype: float32\n",
      "Attributes:\n",
      "index:\n",
      "   startidx         starttime   length  frequency\n",
      "0         0  1542037140620000  2150000     125.00\n",
      "1   2150000  1542054356040000   577500     125.00\n",
      "2   2727500  1542058987770000   631875     125.00\n",
      "3   3359375  1542066174300000  5091882     125.00\n",
      "4   8451257  1542106931080000   217500     125.00\n",
      "5   8668757  1542108684290000     9965     125.00\n",
      "6   8678722  1542109872760000  9709462     125.00\n",
      "location: ['']\n",
      "metric: ['']\n",
      "modality: ['oxhg_r']\n",
      "quality:\n",
      "               time  value\n",
      "0  1542037140620000      0\n",
      "source: ['Intellivue']\n",
      "units: ['']\n",
      "Dataset: waves/pleth, shape: (17861333,), dtype: float32\n",
      "Attributes:\n",
      "index:\n",
      "   startidx         starttime   length  frequency\n",
      "0         0  1542037050315000     6249     125.00\n",
      "1      6249  1542037140620000  2150000     125.00\n",
      "2   2156249  1542058987770000   631875     125.00\n",
      "3   2788124  1542064067940000   261876     125.00\n",
      "4   3050000  1542066174300000  5091882     125.00\n",
      "5   8141882  1542108684290000     9965     125.00\n",
      "6   8151847  1542109872760000  9709486     125.00\n",
      "location: ['']\n",
      "metric: ['']\n",
      "modality: ['pleth']\n",
      "quality:\n",
      "               time  value\n",
      "0  1542037050315000      0\n",
      "source: ['Intellivue']\n",
      "units: ['']\n",
      "Dataset: waves/scthg_l, shape: (18388184,), dtype: float32\n",
      "Attributes:\n",
      "index:\n",
      "   startidx         starttime   length  frequency\n",
      "0         0  1542037140620000  2150000     125.00\n",
      "1   2150000  1542054356040000   577500     125.00\n",
      "2   2727500  1542058987770000   631875     125.00\n",
      "3   3359375  1542066174300000  5091882     125.00\n",
      "4   8451257  1542106931080000   217500     125.00\n",
      "5   8668757  1542108684290000     9965     125.00\n",
      "6   8678722  1542109872760000  9709462     125.00\n",
      "location: ['']\n",
      "metric: ['']\n",
      "modality: ['scthg_l']\n",
      "quality:\n",
      "               time  value\n",
      "0  1542037140620000      0\n",
      "source: ['Intellivue']\n",
      "units: ['mg/dl']\n",
      "Dataset: waves/scthg_r, shape: (18388184,), dtype: float32\n",
      "Attributes:\n",
      "index:\n",
      "   startidx         starttime   length  frequency\n",
      "0         0  1542037140620000  2150000     125.00\n",
      "1   2150000  1542054356040000   577500     125.00\n",
      "2   2727500  1542058987770000   631875     125.00\n",
      "3   3359375  1542066174300000  5091882     125.00\n",
      "4   8451257  1542106931080000   217500     125.00\n",
      "5   8668757  1542108684290000     9965     125.00\n",
      "6   8678722  1542109872760000  9709462     125.00\n",
      "location: ['']\n",
      "metric: ['']\n",
      "modality: ['scthg_r']\n",
      "quality:\n",
      "               time  value\n",
      "0  1542037140620000      0\n",
      "source: ['Intellivue']\n",
      "units: ['mg/dl']\n",
      "Dataset: waves/sthg_index_l, shape: (18388184,), dtype: float32\n",
      "Attributes:\n",
      "index:\n",
      "   startidx         starttime   length  frequency\n",
      "0         0  1542037140620000  2150000     125.00\n",
      "1   2150000  1542054356040000   577500     125.00\n",
      "2   2727500  1542058987770000   631875     125.00\n",
      "3   3359375  1542066174300000  5091882     125.00\n",
      "4   8451257  1542106931080000   217500     125.00\n",
      "5   8668757  1542108684290000     9965     125.00\n",
      "6   8678722  1542109872760000  9709462     125.00\n",
      "location: ['']\n",
      "metric: ['']\n",
      "modality: ['sthg_index_l']\n",
      "quality:\n",
      "               time  value\n",
      "0  1542037140620000      0\n",
      "source: ['Intellivue']\n",
      "units: ['']\n",
      "Dataset: waves/sthg_index_r, shape: (18388184,), dtype: float32\n",
      "Attributes:\n",
      "index:\n",
      "   startidx         starttime   length  frequency\n",
      "0         0  1542037140620000  2150000     125.00\n",
      "1   2150000  1542054356040000   577500     125.00\n",
      "2   2727500  1542058987770000   631875     125.00\n",
      "3   3359375  1542066174300000  5091882     125.00\n",
      "4   8451257  1542106931080000   217500     125.00\n",
      "5   8668757  1542108684290000     9965     125.00\n",
      "6   8678722  1542109872760000  9709462     125.00\n",
      "location: ['']\n",
      "metric: ['']\n",
      "modality: ['sthg_index_r']\n",
      "quality:\n",
      "               time  value\n",
      "0  1542037140620000      0\n",
      "source: ['Intellivue']\n",
      "units: ['']\n"
     ]
    }
   ],
   "source": [
    "# summarize random example file\n",
    "print(f\"Summarizing example file {example_file}:\")\n",
    "h5py_summarize(os.path.join(raw_data_path, example_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43e03bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    indicator                                        description\n",
      "0           0                             b'Data Quality Normal'\n",
      "1           1                                b'Alarms Inhibited'\n",
      "2           2                            b'Measurement In Alarm'\n",
      "3          32                             b'Measurement Ongoing'\n",
      "4          64                                b'Early Indication'\n",
      "5         128                                  b'Validated Data'\n",
      "6        1024                                       b'Demo Data'\n",
      "7        2048                                       b'Test Data'\n",
      "8        4096                             b'Calibration Ongoing'\n",
      "9        8192                                b'Data Unavailable'\n",
      "10      16384                               b'Questionable Data'\n",
      "11      32768                                    b'Invalid Data'\n",
      "12      65536                              b'Value Out Of Range'\n",
      "13     131072                                b'Module Unplugged'\n",
      "14     262144                         b'Transducer Disconnected'\n",
      "15     524288                        b'High electrode impedance'\n",
      "16    1048576                   b'Electrode impedance imbalance'\n",
      "17    2097152                     b'Unknown electrode impedance'\n",
      "18    4194304                           b'Electrode(s) detached'\n",
      "19    8388608                               b'Poor Data Quality'\n",
      "20   16777216                        b'Conceptional Age Unknown'\n",
      "21   33554432                        b'Suppress Display of Data'\n",
      "22   67108864              b'Abnormally low electrode impedance'\n",
      "23  134217728                              b'Electrode Disabled'\n",
      "24  268435456  b'Unapproved Source (source monitor not confir...\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(os.path.join(raw_data_path, example_file), \"r\") as f:\n",
    "    print(pd.DataFrame(f[\"definitions/qualityRef\"][:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eff29cb",
   "metadata": {},
   "source": [
    "Now here we summarize the various data series to observe units and distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e6b94a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing statistics for numerics and waveforms in file 657.icmh5:\n",
      "Dataset: hr\n",
      "Number of missing values: 577\n",
      "               0\n",
      "count 142,309.00\n",
      "mean       77.51\n",
      "std         8.04\n",
      "min         0.00\n",
      "25%        71.99\n",
      "50%        77.99\n",
      "75%        82.99\n",
      "max       155.99\n",
      "\n",
      "\n",
      "Dataset: rr\n",
      "Number of missing values: 4571\n",
      "               0\n",
      "count 138,315.00\n",
      "mean       18.65\n",
      "std         3.33\n",
      "min        -0.00\n",
      "25%        17.00\n",
      "50%        19.00\n",
      "75%        21.00\n",
      "max        44.00\n",
      "\n",
      "\n",
      "Dataset: rso2l\n",
      "Number of missing values: 285\n",
      "               0\n",
      "count 146,815.00\n",
      "mean       67.95\n",
      "std         7.18\n",
      "min         0.00\n",
      "25%        63.20\n",
      "50%        64.70\n",
      "75%        71.60\n",
      "max       100.00\n",
      "\n",
      "\n",
      "Dataset: rso2r\n",
      "Number of missing values: 13\n",
      "               0\n",
      "count 147,087.00\n",
      "mean       68.99\n",
      "std         5.39\n",
      "min         0.00\n",
      "25%        64.60\n",
      "50%        69.80\n",
      "75%        71.80\n",
      "max        97.80\n",
      "\n",
      "\n",
      "Dataset: spo2\n",
      "Number of missing values: 0\n",
      "               0\n",
      "count 142,886.00\n",
      "mean       99.12\n",
      "std         1.12\n",
      "min         0.00\n",
      "25%        99.00\n",
      "50%        99.00\n",
      "75%       100.00\n",
      "max       100.00\n",
      "\n",
      "\n",
      "Dataset: t\n",
      "Number of missing values: 4\n",
      "               0\n",
      "count 142,882.00\n",
      "mean       -0.00\n",
      "std         0.00\n",
      "min        -0.00\n",
      "25%        -0.00\n",
      "50%        -0.00\n",
      "75%        -0.00\n",
      "max        -0.00\n",
      "\n",
      "\n",
      "Dataset: abp\n",
      "Number of missing values: 7111290\n",
      "                  0\n",
      "count 10,750,043.00\n",
      "mean          94.74\n",
      "std           34.46\n",
      "min          -50.01\n",
      "25%           67.68\n",
      "50%           83.92\n",
      "75%          123.08\n",
      "max          299.99\n",
      "\n",
      "\n",
      "Dataset: cvp\n",
      "Number of missing values: 17861332\n",
      "               0\n",
      "count       1.00\n",
      "mean        0.00\n",
      "std          NaN\n",
      "min         0.00\n",
      "25%         0.00\n",
      "50%         0.00\n",
      "75%         0.00\n",
      "max         0.00\n",
      "\n",
      "\n",
      "Dataset: deoxhg_l\n",
      "Number of missing values: 3851\n",
      "                  0\n",
      "count 18,384,333.00\n",
      "mean          -5.01\n",
      "std            9.84\n",
      "min          -49.70\n",
      "25%           -5.00\n",
      "50%           -1.60\n",
      "75%            0.10\n",
      "max           48.90\n",
      "\n",
      "\n",
      "Dataset: deoxhg_r\n",
      "Number of missing values: 245\n",
      "                  0\n",
      "count 18,387,939.00\n",
      "mean          -3.65\n",
      "std            8.18\n",
      "min          -49.80\n",
      "25%           -3.90\n",
      "50%           -1.00\n",
      "75%            1.40\n",
      "max           29.60\n",
      "\n",
      "\n",
      "Dataset: ecg.ii\n",
      "Number of missing values: 17565\n",
      "                  0\n",
      "count 71,427,778.00\n",
      "mean          -0.01\n",
      "std            0.14\n",
      "min           -1.98\n",
      "25%           -0.07\n",
      "50%           -0.03\n",
      "75%            0.01\n",
      "max            2.00\n",
      "\n",
      "\n",
      "Dataset: icp\n",
      "Number of missing values: 17861332\n",
      "               0\n",
      "count       1.00\n",
      "mean        0.00\n",
      "std          NaN\n",
      "min         0.00\n",
      "25%         0.00\n",
      "50%         0.00\n",
      "75%         0.00\n",
      "max         0.00\n",
      "\n",
      "\n",
      "Dataset: oxhg_l\n",
      "Number of missing values: 837312\n",
      "                  0\n",
      "count 17,550,872.00\n",
      "mean          -3.99\n",
      "std            9.60\n",
      "min          -49.90\n",
      "25%           -3.90\n",
      "50%           -1.60\n",
      "75%            1.40\n",
      "max           46.20\n",
      "\n",
      "\n",
      "Dataset: oxhg_r\n",
      "Number of missing values: 617137\n",
      "                  0\n",
      "count 17,771,047.00\n",
      "mean          -0.52\n",
      "std            7.43\n",
      "min          -49.80\n",
      "25%           -1.90\n",
      "50%            1.50\n",
      "75%            4.00\n",
      "max           40.10\n",
      "\n",
      "\n",
      "Dataset: pleth\n",
      "Number of missing values: 17861332\n",
      "               0\n",
      "count       1.00\n",
      "mean        0.00\n",
      "std          NaN\n",
      "min         0.00\n",
      "25%         0.00\n",
      "50%         0.00\n",
      "75%         0.00\n",
      "max         0.00\n",
      "\n",
      "\n",
      "Dataset: scthg_l\n",
      "Number of missing values: 2957730\n",
      "                  0\n",
      "count 15,430,454.00\n",
      "mean          -0.54\n",
      "std            2.05\n",
      "min          -24.60\n",
      "25%           -1.60\n",
      "50%           -0.70\n",
      "75%            0.70\n",
      "max            7.10\n",
      "\n",
      "\n",
      "Dataset: scthg_r\n",
      "Number of missing values: 6043548\n",
      "                  0\n",
      "count 12,344,636.00\n",
      "mean           0.11\n",
      "std            2.25\n",
      "min          -24.90\n",
      "25%           -0.60\n",
      "50%            0.20\n",
      "75%            1.50\n",
      "max            6.10\n",
      "\n",
      "\n",
      "Dataset: sthg_index_l\n",
      "Number of missing values: 3551\n",
      "                  0\n",
      "count 18,384,633.00\n",
      "mean          57.21\n",
      "std           24.40\n",
      "min          -96.91\n",
      "25%           59.50\n",
      "50%           64.10\n",
      "75%           69.60\n",
      "max           98.80\n",
      "\n",
      "\n",
      "Dataset: sthg_index_r\n",
      "Number of missing values: 416\n",
      "                  0\n",
      "count 18,387,768.00\n",
      "mean          58.70\n",
      "std           24.23\n",
      "min          -93.91\n",
      "25%           58.60\n",
      "50%           67.70\n",
      "75%           73.60\n",
      "max           91.90\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# summarize numerics and waveforms\n",
    "def summarize_series(name, obj, invalid_value=invalid_value):\n",
    "    print(f\"Dataset: {name}\")\n",
    "    df = pd.DataFrame(obj[:])\n",
    "    df.replace(invalid_value, np.nan, inplace=True)\n",
    "    print(f\"Number of missing values: {df.isna().sum().sum()}\")\n",
    "    print(df.describe())\n",
    "    print(\"\\n\")\n",
    "    return\n",
    "\n",
    "print(f\"Summarizing statistics for numerics and waveforms in file {example_file}:\")\n",
    "with h5py.File(os.path.join(raw_data_path, example_file), \"r\") as f:\n",
    "    f[\"numerics\"].visititems(summarize_series)\n",
    "    f[\"waves\"].visititems(summarize_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0adb72",
   "metadata": {},
   "source": [
    "#### Plot a random file\n",
    "\n",
    "Here we plot the various data series of a random file to observe their dynamics. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f120278d",
   "metadata": {},
   "source": [
    "##### Timeseries data\n",
    "\n",
    "First we can just naively plot a data series without considering data gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ec374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(os.path.join(raw_data_path, example_file), \"r\") as f:\n",
    "    df = pd.DataFrame(f[\"numerics/hr\"])\n",
    "    df.replace(invalid_value, np.nan, inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.scatter(df.index/(60*60), df[0], label = \"Heart Rate\", s=0.5)\n",
    "ax.set_xlabel(\"Time (hr)\")\n",
    "ax.set_ylabel(\"Heart Rate (bpm)\")\n",
    "ax.set_title(\"Heart Rate over Time\")\n",
    "ax.set_ylim(25, 200)\n",
    "img_name = f\"hr_series_{example_file.removesuffix('.icmh5')}_nogaps.png\"\n",
    "plt.savefig(os.path.join(img_dir, img_name), bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd3e47d",
   "metadata": {},
   "source": [
    "However, there are gaps in this data, as seen in the ``index`` attribute of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c24867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot continuous time series with gaps as NaNs\n",
    "with h5py.File(os.path.join(raw_data_path, example_file), \"r\") as f:\n",
    "    df = build_continuous_time(f, 'numerics/hr')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.scatter(df.index/(60*60), df[0], label = \"Heart Rate\", s=0.5)\n",
    "ax.set_xlabel(\"Time (hr)\")\n",
    "ax.set_ylabel(\"Heart Rate (bpm)\")\n",
    "ax.set_title(\"Heart Rate over Time with recording gaps\")\n",
    "ax.set_ylim(25, 200)\n",
    "\n",
    "img_name = f\"hr_series_{example_file.removesuffix('.icmh5')}_full.png\"\n",
    "fig.savefig(os.path.join(img_dir, img_name), bbox_inches='tight')\n",
    "fig.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53f8399",
   "metadata": {},
   "source": [
    "##### Distribution of recording variables\n",
    "\n",
    "Next we can investigate the general distribution of all the variables of a random recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c460a03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can do histograms for all numerics\n",
    "with h5py.File(os.path.join(raw_data_path, example_file), \"r\") as f:\n",
    "    grp = f[\"numerics\"]\n",
    "    nrows = int(np.sqrt(len(numerics)))\n",
    "    ncols = len(numerics)//nrows + (len(numerics)%nrows)%nrows\n",
    "    fig, axs = plt.subplots(nrows = nrows, ncols = ncols, layout='constrained', figsize=(5* (len(numerics)//2 + 1), 8))\n",
    "    for i, n in enumerate(numerics):\n",
    "        df = pd.DataFrame(grp[n])\n",
    "        df.replace(invalid_value, np.nan, inplace=True)\n",
    "        ax = axs[i//ncols, i%ncols]\n",
    "        if n == \"t\":\n",
    "            ax.hist(df[0], bins=\"auto\", density=True, label=\"Distribution\")\n",
    "        else:\n",
    "            sns.kdeplot(df[0], ax=ax, fill=True, bw_adjust=3, label=\"Distribution\")\n",
    "        if n == \"spo2\":\n",
    "            ax.set_xlim(70, 110)\n",
    "        ax.set_ylabel(\"Density\")\n",
    "        ax.set_xlabel(\"Value\")\n",
    "        ax.set_title(n + f\" Distribution (Invalid Values = {df[0].isna().sum()/ len(df)*100:.3f}%)\")\n",
    "        mean_value = df[0].mean()\n",
    "        ax.axvline(x=mean_value, color='red', linestyle='--', label=f'Mean: {mean_value:.2f}')\n",
    "        ax.legend()\n",
    "    \n",
    "fig.suptitle(f\"Histogram of numeric values for file {example_file}\")\n",
    "img_name = f\"numerics_hist_{example_file.removesuffix('.icmh5')}.png\"\n",
    "plt.savefig(os.path.join(img_dir, img_name))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63ac274",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(waves)\n",
    "waves.remove(\"ecg.ii\") # it does not make sense to plot distribution of ECG voltages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82903f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can do histograms for all waves\n",
    "with h5py.File(os.path.join(raw_data_path, example_file), \"r\") as f:\n",
    "    grp = f[\"waves\"]\n",
    "    nrows = int(np.sqrt(len(waves)))\n",
    "    ncols = len(waves)//nrows + (len(waves)%nrows)%nrows\n",
    "    fig, axs = plt.subplots(nrows = nrows, ncols = ncols, layout='constrained', figsize=(8*ncols, 4*nrows))\n",
    "    for i, n in tqdm(enumerate(waves)):\n",
    "        df = pd.DataFrame(grp[n])\n",
    "        df.replace(invalid_value, np.nan, inplace=True)\n",
    "        ax = axs[i//ncols, i%ncols]\n",
    "        if n == \"cvp\" or n == \"pleth\" or n == \"icp\":\n",
    "            ax.hist(df[0], bins=\"auto\", density=True, label=\"Distribution\")\n",
    "        else:\n",
    "            sns.kdeplot(df[0], ax=ax, fill=True, bw_adjust=3, label=\"Distribution\")\n",
    "        if n == \"spo2\":\n",
    "            ax.set_xlim(70, 110)\n",
    "        ax.set_ylabel(\"Density\")\n",
    "        ax.set_xlabel(\"Value\")\n",
    "        ax.set_title(n + f\" Distribution (Invalid Values = {df[0].isna().sum()/ len(df)*100:.3f}%)\")\n",
    "        mean_value = df[0].mean()\n",
    "        ax.axvline(x=mean_value, color='red', linestyle='--', label=f'Mean: {mean_value:.2f}')\n",
    "        ax.legend()\n",
    "\n",
    "for i, a in enumerate(axs.flat):\n",
    "    if i > len(waves) - 1:\n",
    "        a.set_axis_off()\n",
    "\n",
    "fig.suptitle(f\"Histogram of waves values for file {example_file}\")\n",
    "img_name = f\"waves_hist_{example_file.removesuffix('.icmh5')}.png\"\n",
    "plt.savefig(os.path.join(img_dir, img_name))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1066a220",
   "metadata": {},
   "source": [
    "### Database-Wide Statistics\n",
    "\n",
    "In this section, we plot some database-wide statistics to obtain summaries of the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb6001f",
   "metadata": {},
   "source": [
    "#### Variables recorded per patient by count\n",
    "\n",
    "Not every patient has the same variables recorded. To select the best ones, we need some statistics on which proportion of patients have which variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6781cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e20153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find variables of patients\n",
    "recorded_vars = Counter()\n",
    "for i, file in tqdm(enumerate(h5py_files)):\n",
    "    with h5py.File(os.path.join(raw_data_path, file), \"r\") as f:\n",
    "        if invalid_value != float(f.attrs[\"invalidValue\"][0]):\n",
    "            print(\"Invalid value is different, problem\")\n",
    "            print(f\"Invalid value: {float(f.attrs['invalidValue'][0])}\")\n",
    "        \n",
    "        numerics = list(f[\"numerics\"].keys())\n",
    "        waves = list(f[\"waves\"].keys())\n",
    "        f_counter = Counter(numerics) + Counter(waves)\n",
    "        recorded_vars += f_counter\n",
    "\n",
    "vars_per_dataset = pd.Series(dict(recorded_vars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229b881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_per_dataset.sort_values(inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4d33b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context({'ytick.left': True, 'xtick.bottom': True}):\n",
    "    fig, ax = plt.subplots(figsize=(8,15))\n",
    "    \n",
    "    sns.barplot(data=vars_per_dataset / len(h5py_files) * 100, orient=\"h\", edgecolor=\"black\", width = 0.8, ax=ax)\n",
    "    \n",
    "    ax.set_title('Variables Recorded per Patient')\n",
    "    \n",
    "    ax.set_ylabel('Variable')\n",
    "    ax.tick_params(axis='y', labelsize=14)\n",
    "\n",
    "    ax.set_xlabel('Percentage of Patients with Recorded Data')\n",
    "    ax.set_xticks(np.arange(0, 101, 5), minor=True)\n",
    "    ax.set_xlim(0, 100)\n",
    "\n",
    "    img_name = f\"variable_coverage.png\"\n",
    "    plt.savefig(os.path.join(img_dir, img_name), bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9b5f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_per_dataset.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3dcc39",
   "metadata": {},
   "source": [
    "#### Durations with and without gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a87fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all the files and extract duration in seconds with gaps\n",
    "durations_gaps = {}\n",
    "\n",
    "for i, file in tqdm(enumerate(h5py_files)):\n",
    "    key = [s.split(\".\") for s in file.split(\"_\")][0][0]\n",
    "\n",
    "    with h5py.File(os.path.join(raw_data_path, file), \"r\") as f:\n",
    "        # duration with gaps\n",
    "        time = int(f.attrs[\"duration\"][0].replace(\" seconds\", \"\"))\n",
    "        durations_gaps[key] = time + durations_gaps.get(key, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2883add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all the files and extract duration in seconds without gaps\n",
    "durations_no_gaps = {}\n",
    "\n",
    "for i, file in tqdm(enumerate(h5py_files)):\n",
    "    key = [s.split(\".\") for s in file.split(\"_\")][0][0]\n",
    "\n",
    "    with h5py.File(os.path.join(raw_data_path, file), \"r\") as f:\n",
    "        # duration without gaps\n",
    "        try:\n",
    "            index = pd.DataFrame(f[\"numerics/hr\"].attrs[\"index\"])\n",
    "            time_per_segment = (index[\"length\"]).astype('float64')/index[\"frequency\"]\n",
    "            time = time_per_segment.sum().item()\n",
    "            durations_no_gaps[key] = time + durations_no_gaps.get(key, 0)\n",
    "        except:\n",
    "            print(f\"numerics/hr not found in {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b2c5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot violin plots of durations with and without gaps\n",
    "\n",
    "df1 = pd.DataFrame({'Value': np.array(list(durations_no_gaps.values()))/(60*60), 'Group': 'Excluding Gaps'})\n",
    "df2 = pd.DataFrame({'Value': np.array(list(durations_gaps.values()))/(60*60), 'Group': 'Including Gaps'})\n",
    "\n",
    "# Concatenate the two DataFrames\n",
    "combined_df = pd.concat([df1, df2])\n",
    "medians = combined_df.groupby(['Group'])['Value'].median()\n",
    "\n",
    "with plt.rc_context({'ytick.left': True}):\n",
    "        with sns.axes_style(\"darkgrid\"):\n",
    "                fig, ax = plt.subplots(figsize=(12,6))\n",
    "                sns.violinplot(x='Group', y='Value', data=combined_df, ax=ax, hue=\"Group\", palette=\"pastel\")\n",
    "                ax.set_title('Side-by-Side Violinplots of Dataset Durations')\n",
    "                ax.set_ylabel('Duration (hours)')\n",
    "                ax.set_xlabel('')\n",
    "                ax.set_yticks(np.arange(0, 251, 25), minor=True)\n",
    "                ax.set_ylim(0, 250)\n",
    "\n",
    "                for i, v in enumerate(medians):\n",
    "                        ax.text((i+0.025), (v-2), str(round(v, 2)), fontsize = 12)\n",
    "\n",
    "                img_name = f\"duration_distributions.png\"\n",
    "                plt.savefig(os.path.join(img_dir, img_name), bbox_inches='tight')\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4c5741",
   "metadata": {},
   "source": [
    "#### Global distributions of all raw variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf5aaba",
   "metadata": {},
   "source": [
    "We will drop the variables that are not recorded for >80% of patients, as that will only be a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5353c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9896b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = vars_per_dataset / len(h5py_files) > 0.80\n",
    "vars_per_dataset = vars_per_dataset[mask]\n",
    "print(vars_per_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16659b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_method = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b421ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_histograms(existing_hist, existing_edges, new_data, bins='auto'):\n",
    "    # If we don't yet have global bins, define them from new_data\n",
    "    if existing_edges is None:\n",
    "        hist, bin_edges = np.histogram(new_data, bins=bins)\n",
    "        return hist, bin_edges\n",
    "    \n",
    "    # Re-bin new_data to existing edges\n",
    "    hist, _ = np.histogram(new_data, bins=existing_edges)\n",
    "    existing_hist += hist\n",
    "    return existing_hist, existing_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4d496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_feature(feature, h5py_files, raw_data_path, bin_method, invalid_value, batch_size):\n",
    "    global_hist, global_edges = None, None\n",
    "    invalid_count = 0\n",
    "    length = 0\n",
    "    batch = []\n",
    "    for i, file in enumerate(h5py_files):\n",
    "        with h5py.File(os.path.join(raw_data_path, file), \"r\") as f:\n",
    "            for var_type in [\"waves\", \"numerics\"]:\n",
    "                if feature in f[f\"{var_type}\"].keys():\n",
    "                    var = var_type\n",
    "                    try:\n",
    "                        data = f[f\"{var_type}/{feature}\"][:]\n",
    "                        data[data == invalid_value] = np.nan\n",
    "                        valid = np.isfinite(data)\n",
    "                        length += data.shape[0]\n",
    "                        invalid_count += (~valid).sum()\n",
    "                        data = data[valid]\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "                    if len(batch) < batch_size:\n",
    "                        batch.append(data)\n",
    "                    else:\n",
    "                        merged = np.concatenate(batch)\n",
    "                        global_hist, global_edges = merge_histograms(global_hist, global_edges, merged, bins=bin_method)\n",
    "                        batch.clear()\n",
    "                else:\n",
    "                    continue\n",
    "    total_counts = global_hist.sum()\n",
    "    if total_counts == 0:\n",
    "        total_counts = 1\n",
    "    result_dict = {\"hist\": global_hist / total_counts, \"edges\":global_edges, \"var\": var, \"invalid_frac\": invalid_count / length}   \n",
    "    return feature, result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a4e088",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProcessPoolExecutor(max_workers=8) as ex:\n",
    "    results = list(tqdm(ex.map(partial(process_feature,\n",
    "                             h5py_files=h5py_files,\n",
    "                             raw_data_path=raw_data_path,\n",
    "                             bin_method=bin_method,\n",
    "                             invalid_value=invalid_value,\n",
    "                             batch_size=10),\n",
    "                     vars_per_dataset.index)))\n",
    "\n",
    "distributions = dict(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5d1f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(distributions[\"hr\"][\"invalid_frac\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a53bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = {f: distributions[f] for f in distributions.keys() if distributions[f][\"var\"] == 'numerics'}\n",
    "wave_features = {f: distributions[f] for f in distributions.keys() if distributions[f][\"var\"] == 'waves'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ea25da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can do histograms for all numerics\n",
    "numerics = list(numeric_features.keys())\n",
    "waves = list(wave_features.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce94a918",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = int(np.sqrt(len(numerics)))\n",
    "ncols = len(numerics)//nrows + (len(numerics)%nrows)%nrows\n",
    "fig, axs = plt.subplots(nrows = nrows, ncols = ncols, layout='constrained', figsize=(5* (len(numerics)//2 + 1), 8))\n",
    "for i, n in enumerate(numerics):\n",
    "    edges = distributions[n][\"edges\"]\n",
    "    hist = distributions[n][\"hist\"]\n",
    "    ax = axs[i//ncols, i%ncols]\n",
    "    sns.barplot(x=edges[:-1], y=hist, ax=ax, native_scale=True, edgecolor=\"black\", width=1)\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.set_xlabel(\"Value\")\n",
    "    ax.set_title(n + f\" Distribution (Invalid Values = {distributions[n]['invalid_frac'].item() * 100:.3f}%)\")\n",
    "    mean_value = (hist * edges[:-1]).sum()\n",
    "    ax.axvline(x=mean_value, color='red', linestyle='--', label=f'Approximate Mean: {mean_value:.2f}')\n",
    "    ax.legend()\n",
    "    \n",
    "fig.suptitle(f\"Histogram of numeric values\")\n",
    "img_name = f\"numerics_hist_alldata.png\"\n",
    "plt.savefig(os.path.join(img_dir, img_name))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fec191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can do histograms for all waves\n",
    "nrows = int(np.sqrt(len(waves)))\n",
    "ncols = len(waves)//nrows + (len(waves)%nrows)%nrows\n",
    "fig, axs = plt.subplots(nrows = nrows, ncols = ncols, layout='constrained', figsize=(8*ncols, 4*nrows))\n",
    "for i, n in enumerate(waves):\n",
    "    edges = distributions[n][\"edges\"]\n",
    "    hist = distributions[n][\"hist\"]\n",
    "    ax = axs[i//ncols, i%ncols]\n",
    "    sns.barplot(x=edges[:-1], y=hist, ax=ax, native_scale=True, edgecolor=\"black\", width=1)\n",
    "    # if n == \"cvp\" or n == \"pleth\" or n == \"icp\":\n",
    "    #     ax.hist(df[0], bins=\"auto\", density=True, label=\"Distribution\")\n",
    "    # else:\n",
    "    #     sns.kdeplot(df[0], ax=ax, fill=True, bw_adjust=3, label=\"Distribution\")\n",
    "    # if n == \"spo2\":\n",
    "    #     ax.set_xlim(70, 110)\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.set_xlabel(\"Value\")\n",
    "    ax.set_title(n + f\" Distribution (Invalid Values = {distributions[n]['invalid_frac'].item() * 100:.3f}%)\")\n",
    "    mean_value = (hist * edges[:-1]).sum()\n",
    "    ax.axvline(x=mean_value, color='red', linestyle='--', label=f'Approximate Mean: {mean_value:.2f}')\n",
    "    ax.legend()\n",
    "\n",
    "for i, a in enumerate(axs.flat):\n",
    "    if i > len(waves) - 1:\n",
    "        a.set_axis_off()\n",
    "\n",
    "fig.suptitle(f\"Histogram of waveform data\")\n",
    "img_name = f\"waves_hist_alldata.png\"\n",
    "# plt.savefig(os.path.join(img_dir, img_name))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1556fb70",
   "metadata": {},
   "source": [
    "### Labels\n",
    "\n",
    "Now, let us explore the label dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4a5f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptid_raw_list = [fpath.split(\".\")[0] for fpath in os.listdir(raw_data_path) if fpath.endswith(\".icmh5\")]\n",
    "\n",
    "# remove patients for which no labels\n",
    "ptid_list = [f for f in ptid_raw_list if f.split(\"_\")[0] + \"_updated.csv\" in os.listdir(labels_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3036a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random label file\n",
    "r_id = ptid_list[np.random.randint(0, len(ptid_list))]\n",
    "df = load_label(r_id, labels_path=labels_path, time=\"s\")\n",
    "print(r_id)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0332a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df, find seconds elapsed to calculate opt MAP\n",
    "calc = TARGETS\n",
    "start_times = {fpath.split(\".\")[0] : h5py.File(os.path.join(raw_data_path, fpath), \"r\").attrs[\"dataStartTimeUnix\"][0] for fpath in os.listdir(raw_data_path) if fpath.split(\".\")[0]in ptid_list}\n",
    "elapsed_times = pd.Series([find_time_elapsed(pt, calc, labels_path, start_time=int(start_times[pt]), time='s') for pt in tqdm(ptid_list)]).dropna()\n",
    "print(elapsed_times.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc6378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(start_times[\"690_1\"], start_times[\"690_2\"], start_times[\"690_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cbbfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_times = elapsed_times[elapsed_times > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3d9226",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_data = elapsed_times.shape[0]\n",
    "all_pt = len(ptid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d65fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(elapsed_times.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc29a5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context({'xtick.bottom': True, 'ytick.left': True}):\n",
    "    fig, ax = plt.subplots(figsize=(12,6))\n",
    "    sns.histplot(data=pd.Series(elapsed_times)/(60*60), ax=ax, kde=True, stat=\"probability\", kde_kws={'bw_adjust': 0.4})\n",
    "    ax.set_title(f\"Time required to calculate limits of autoregulation (calculated for {with_data}/{all_pt} patients)\")\n",
    "    ax.set_xlabel('Time (hours)')\n",
    "    ax.set_ylabel(\"Fraction of Patients\")\n",
    "    ax.set_xticks(np.arange(0, 20, 0.5), minor=True)\n",
    "    ax.set_xlim(0, 20)\n",
    "\n",
    "    mean_value = (pd.Series(elapsed_times)/(60*60)).mean()\n",
    "    ax.axvline(x=mean_value, color='red', linestyle='--', label=f'Mean: {mean_value:.2f} hours')\n",
    "    ax.legend()\n",
    "\n",
    "    med_value = (pd.Series(elapsed_times)/(60*60)).median()\n",
    "    ax.axvline(x=med_value, color='green', linestyle='--', label=f'Median: {med_value:.2f} hours')\n",
    "    ax.legend()\n",
    "    \n",
    "\n",
    "\n",
    "    img_name = f\"mapopt_calc_distributions.png\"\n",
    "    plt.savefig(os.path.join(img_dir, img_name), bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5672642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
