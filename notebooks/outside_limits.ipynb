{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1571a50",
   "metadata": {},
   "source": [
    "## Limits of Autoregulation - Summary Statistics\n",
    "\n",
    "In this notebook we look at the characteristics of the physiologic data when patients move from inside to outside the limits of autoregulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42fd7eb",
   "metadata": {},
   "source": [
    "#### Useful Imports and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ffe5941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")  # add project root\n",
    "\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data_utils import *\n",
    "from src.constants import *\n",
    "\n",
    "# pending useful sklearn imports\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca1de434",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:10,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf60b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    'xtick.bottom': True,\n",
    "    'ytick.left': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "241d281f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6292b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(context=\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "708d2029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path constants\n",
    "data_dir = \"/home/mr2238/project_pi_np442/mr2238/accelerate/data\"\n",
    "img_dir = \"/home/mr2238/project_pi_np442/mr2238/accelerate/imgs/in_out\"\n",
    "global_path = \"/home/mr2238/project_pi_np442/mr2238/accelerate/data/processed/all_data.hdf5\"\n",
    "labels_path = os.path.join(data_dir, \"labels\")\n",
    "raw_data_path = os.path.join(data_dir, \"raw_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99d82a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check img directory exists, if not make it\n",
    "os.makedirs(img_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e0e25f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of h5py files: 215\n",
      "Example file: 1002.icmh5\n"
     ]
    }
   ],
   "source": [
    "# list files\n",
    "h5py_files = [f for f in os.listdir(raw_data_path) if f.endswith(\".icmh5\")]\n",
    "print(f\"Number of h5py files: {len(h5py_files)}\")\n",
    "print(f\"Example file: {h5py_files[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5ae6de",
   "metadata": {},
   "source": [
    "### In and Out Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf98a97",
   "metadata": {},
   "source": [
    "#### Define Limits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed7f55a",
   "metadata": {},
   "source": [
    "Here we explore how much a given patient is within their autoregulatory limits, to get a sense of how to distribute this.\n",
    "1) Definition: Patient is outside limits of autoregulation if at a given time *t*, the mean ABP value over the minute prior to time *t* is outside the limits calculated at *t*.\n",
    "2) What do we want?\n",
    "    - Distribution of % time outside limits: Done\n",
    "    - Duration of time outside limits: per patient, distribution, median, average\n",
    "    - Number of times outside limits per patient\n",
    "    - Correlation between time elapsed and likelihood of being outside of limits: t vs. at time t, what fraction of patients are outside limits?\n",
    "    - time spent outside autoregulation vs time to autoregulation calc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff29d7d",
   "metadata": {},
   "source": [
    "#### Percent Time In and Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bcf469",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_false = {}\n",
    "ins = []\n",
    "mode = 'mean'\n",
    "with h5py.File(global_path, \"r\") as f:\n",
    "    for pt in f:\n",
    "        if f[f\"{pt}/processed/in_out_{mode}\"].attrs[\"no_label_overlap\"]:\n",
    "            continue\n",
    "        in_out_df = pd.Series(f[f\"{pt}/processed/in_out_{mode}/in_out\"][...]).astype(bool)\n",
    "        idx_window = pd.DataFrame(f[f\"{pt}/processed/in_out_{mode}/window_idx\"][...])\n",
    "\n",
    "        # to actually get percentage of time spent outside autoregulation, we need to get actual window length, we can't weigh all the windows equally\n",
    "        len_window = idx_window.iloc[:, 1] - idx_window.iloc[:, 0]\n",
    "        in_out = (in_out_df * len_window).sum() / len_window.sum()\n",
    "        if len_window.sum() == 0:\n",
    "            print(pt)\n",
    "            print(idx_window)\n",
    "            print(in_out_df)\n",
    "\n",
    "        true_false[pt] = [in_out]\n",
    "        ins.append(in_out_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4db2f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_false_df = pd.DataFrame(true_false).transpose()\n",
    "bool_in_out_df = pd.concat(ins)\n",
    "bool_in_out_df.describe()\n",
    "true_false_df = true_false_df.rename(columns={true_false_df.columns[0]: 'in_percent'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3908f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate percent time in/out per patient, need to switch because in_out is True if in\n",
    "percent_time = 1- np.array(true_false_df).squeeze()\n",
    "print(percent_time.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89089979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribtion\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "fig.tight_layout(pad=2)\n",
    "sns.histplot(percent_time * 100, ax=ax, stat=\"probability\", edgecolor=(0, 0, 0, 0.5), alpha=0.5)\n",
    "# sns.kdeplot(\n",
    "#     percent_time / percent_time.sum(),\n",
    "#     ax=ax,\n",
    "#     bw_adjust=1,\n",
    "#     linewidth=2,\n",
    "#     cut=0,\n",
    "# )\n",
    "ax.set_title(f\"Percentage of time spent outside autoregulatory limits ({len(percent_time)} files, 189 patients)\")\n",
    "ax.set_xlabel('Percentage of Time Outside Limits')\n",
    "ax.set_ylabel(\"Fraction of Patients\")\n",
    "ax.set_ylim(0, 0.25)\n",
    "ax.set_xticks(np.arange(0, 1, 0.1), minor=True)\n",
    "\n",
    "mean_value = pd.Series(percent_time).mean()\n",
    "ax.axvline(x=mean_value * 100, color='red', linestyle='--', label=f'Mean: {mean_value * 100:.0f}%')\n",
    "ax.legend()\n",
    "\n",
    "med_value = pd.Series(percent_time).median()\n",
    "ax.axvline(x=med_value * 100, color='green', linestyle='--', label=f'Median: {med_value * 100:.0f}%')\n",
    "ax.legend()\n",
    "\n",
    "img_name = f\"in_out_percent_distribution.png\"\n",
    "plt.savefig(os.path.join(img_dir, img_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb125de3",
   "metadata": {},
   "source": [
    "Now, we can correlate this with the time required to calculate MAP opt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6380aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df, find seconds elapsed to calculate opt MAP\n",
    "with h5py.File(global_path, \"r\") as f:\n",
    "    rows = []\n",
    "    calc = TARGETS\n",
    "    for pt in f:\n",
    "        if f[f\"{pt}/processed/in_out_{mode}\"].attrs[\"no_label_overlap\"]:\n",
    "            continue\n",
    "        else:\n",
    "            time_to_mapopt = find_time_elapsed(str(pt), calc, labels_path, time=\"s\", start_time=int(f[f\"{pt}/raw/\"].attrs[\"dataStartTimeUnix\"][0]))\n",
    "            rows.append([time_to_mapopt, str(pt)])\n",
    "    elapsed_times = pd.DataFrame(rows, columns=['time', 'ptid'])\n",
    "    elapsed_times_idx = elapsed_times.set_index('ptid').dropna()\n",
    "    elapsed_times_idx = elapsed_times_idx[elapsed_times_idx > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f3aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "timevpercent = pd.merge(1 - true_false_df, elapsed_times_idx, left_index=True, right_index=True, how='inner')\n",
    "timevpercent = timevpercent.rename(columns={'in_percent' : 'out_percent'})\n",
    "timevpercent = timevpercent[timevpercent['time'] > 0]\n",
    "timevpercent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6fc9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = timevpercent[\"out_percent\"], np.log(timevpercent[\"time\"])\n",
    "r, p = pearsonr(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a45f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot correlation\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "fig.tight_layout(pad=0)\n",
    "sns.regplot(x = x*100, y = np.log(timevpercent[\"time\"]), scatter_kws={'alpha':0.6})\n",
    "ax.set_title(f\"Percentage of Time Outside Autoregulation vs. Time to First MAPopt calculation\\n({timevpercent.shape[0]} files, 189 patients)\")\n",
    "ax.set_xlabel('Percentage of Time Outside Limits')\n",
    "ax.set_ylabel(\"Log Time to MAPopt calculation \\n(log s)\")\n",
    "# ax.set_ylim(7.5, 11)\n",
    "# ax.set_xticks(np.arange(0, 1, 0.1), minor=True)\n",
    "\n",
    "# mean_value = pd.Series(percent_time).mean()\n",
    "# ax.axvline(x=mean_value * 100, color='red', linestyle='--', label=f'Mean: {mean_value * 100:.0f}%')\n",
    "# ax.legend()\n",
    "\n",
    "# med_value = pd.Series(percent_time).median()\n",
    "# ax.axvline(x=med_value * 100, color='green', linestyle='--', label=f'Median: {med_value * 100:.0f}%')\n",
    "# ax.legend()\n",
    "plt.text(0.05, 0.95, f\"r = {r:.2f}\", transform=plt.gca().transAxes, fontsize=12)\n",
    "\n",
    "# img_name = f\"in_out_percent_distribution.png\"\n",
    "# plt.savefig(os.path.join(img_dir, img_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba8003d",
   "metadata": {},
   "source": [
    "Notice there is no correlation. Most likely due to the fact that time to MAPopt calc depends on a time period for which there are no autoregulatory limits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba09fa4",
   "metadata": {},
   "source": [
    "We can also see how the likelihood of being outside the limits is correlated with time elapsed from start of recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cc5004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get in_out for each patient, add n/a if time index is not represented\n",
    "# concat and plot\n",
    "frames = []\n",
    "with h5py.File(global_path, \"r\") as f:\n",
    "    for pt in tqdm(f.keys()):\n",
    "        processed_data_path = f\"{pt}/processed/in_out_{mode}/\"\n",
    "        if f[processed_data_path].attrs[\"no_label_overlap\"]:\n",
    "            continue\n",
    "        label_datetimes = pd.to_datetime(f[processed_data_path + \"label_timestamp\"][...], unit=\"us\", origin=\"unix\")\n",
    "        zero_idx = label_datetimes - pd.to_datetime((f[f\"{pt}/raw\"].attrs[\"dataStartTimeUnix\"]).astype(np.int64) * 1e6, unit=\"us\", origin=\"unix\")[0]\n",
    "        in_out_df = f[f\"{pt}/processed/in_out_{mode}/in_out\"][...]\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            \"timestamp\": zero_idx,\n",
    "            f\"in_out_{pt}\": 1 - in_out_df\n",
    "        })\n",
    "        frames.append(df)\n",
    "\n",
    "continuous_time_grid = pd.concat(frames, axis=0)\n",
    "print(continuous_time_grid.shape)\n",
    "grid_groups = continuous_time_grid.groupby(\"timestamp\", as_index=False)\n",
    "count_per_timestamp = grid_groups.first()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910775c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_per_timestamp['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0144d65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will do min because that looks better\n",
    "agg_counts = pd.DataFrame(count_per_timestamp['timestamp'])\n",
    "agg_counts['sum'] = count_per_timestamp.drop('timestamp', axis = 1).sum(axis=1)\n",
    "hourly_df = agg_counts.resample('min', on='timestamp').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9947c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557215c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot \n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "fig.tight_layout(pad=0)\n",
    "sns.lineplot(x = hourly_df.index/(1e9*60*60), y = hourly_df['sum']/(count_per_timestamp.shape[1] - 1) * 100)\n",
    "ax.set_title(f\"Probability of Outside Autoregulation by Time\\n({count_per_timestamp.shape[1] - 1} files, 189 patients)\")\n",
    "ax.set_xlabel('Time from Recording Start (hours)')\n",
    "ax.set_ylabel(\"Probability Outside of AR Limits (%)\")\n",
    "\n",
    "ax.set_xlim(-5, 100)\n",
    "ax.set_xticks(np.arange(0, 100, 5), minor=True)\n",
    "\n",
    "img_name = f\"in_out_prob_by_time.png\"\n",
    "plt.savefig(os.path.join(img_dir, img_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbc563e",
   "metadata": {},
   "source": [
    "#### Amount of time spent outside of limits\n",
    "\n",
    "We can do this in one minute intervals, basically develop a function that makes a list of segments of interrupted outside status with their lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57313897",
   "metadata": {},
   "outputs": [],
   "source": [
    "minutes_out_per_pt = count_per_timestamp.iloc[:, 1:].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e68ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "minutes_out_per_pt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5d15d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution of minutes out\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "fig.tight_layout(pad=2)\n",
    "sns.histplot(minutes_out_per_pt, ax=ax, stat=\"probability\", edgecolor=(0, 0, 0, 0.5), alpha=0.5,)\n",
    "ax.set_title(f\"Total Time outside Autoregulation ({len(percent_time)} files, 189 patients)\")\n",
    "ax.set_xlabel('Time (min)')\n",
    "ax.set_ylabel(\"Fraction of Patients\")\n",
    "ax.set_ylim(0, 0.25)\n",
    "ax.set_xticks(np.arange(0, 1, 0.1), minor=True)\n",
    "\n",
    "mean_value = minutes_out_per_pt.mean()\n",
    "ax.axvline(x=mean_value, color='red', linestyle='--', label=f'Mean: {mean_value/60:.1f} hrs')\n",
    "ax.legend()\n",
    "\n",
    "med_value = minutes_out_per_pt.median()\n",
    "ax.axvline(x=med_value, color='green', linestyle='--', label=f'Median: {med_value/60:.1f} hrs')\n",
    "ax.legend()\n",
    "\n",
    "img_name = f\"in_out_percent_distribution.png\"\n",
    "# plt.savefig(os.path.join(img_dir, img_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218f8732",
   "metadata": {},
   "outputs": [],
   "source": [
    "minutes_out_per_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a9070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlate that with time to MAPopt calculation (the longer it takes to calculate, the longer they REMAIN outside limits???)\n",
    "# there is a wild outlier where it takes more than 60_000 min to compute time so we will remove\n",
    "# merge time out and minutes_out_per_patient\n",
    "tmp = minutes_out_per_pt.reset_index()\n",
    "tmp['index'] = tmp['index'].str.removeprefix('in_out_')\n",
    "tmp = tmp.set_index('index', drop=True)\n",
    "tmp = tmp.rename(columns={tmp.columns[0] : \"time_out\"})\n",
    "reg_data = pd.merge(tmp, elapsed_times_idx, left_index=True, right_index=True, how='inner').rename(columns={\"time\" : \"time_to_calc\"})\n",
    "filtered = reg_data[reg_data['time_to_calc'] < 60_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cddfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = filtered[\"time_to_calc\"], filtered[\"time_out\"]\n",
    "r, p = pearsonr(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426d44c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot correlation\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "fig.tight_layout(pad=0)\n",
    "sns.regplot(x = x, y =  y, scatter_kws={'alpha':0.6})\n",
    "ax.set_title(f\"Calc to Time Outside\\n({timevpercent.shape[0]} files, 189 patients)\")\n",
    "ax.set_xlabel('Time to Limits Calculation (s)')\n",
    "ax.set_ylabel(\"Time Outside Autoregulation (s)\")\n",
    "# ax.set_ylim(7.5, 11)\n",
    "# ax.set_xticks(np.arange(0, 1, 0.1), minor=True)\n",
    "\n",
    "# mean_value = pd.Series(percent_time).mean()\n",
    "# ax.axvline(x=mean_value * 100, color='red', linestyle='--', label=f'Mean: {mean_value * 100:.0f}%')\n",
    "# ax.legend()\n",
    "\n",
    "# med_value = pd.Series(percent_time).median()\n",
    "# ax.axvline(x=med_value * 100, color='green', linestyle='--', label=f'Median: {med_value * 100:.0f}%')\n",
    "# ax.legend()\n",
    "plt.text(0.05, 0.95, f\"r = {r:.2f}\", transform=plt.gca().transAxes, fontsize=12)\n",
    "\n",
    "# img_name = f\"in_out_percent_distribution.png\"\n",
    "# plt.savefig(os.path.join(img_dir, img_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65486b8",
   "metadata": {},
   "source": [
    "### Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c02188e",
   "metadata": {},
   "source": [
    "#### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaa8068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_time(g, full_timestamps):\n",
    "    g_ts = g.index\n",
    "    t_1 = full_timestamps.get_loc(g_ts[0])\n",
    "    if t_1 > 0:\n",
    "        return full_timestamps[t_1 - 1]\n",
    "    else:\n",
    "        return full_timestamps[t_1] - (60 * 1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdf0363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now consider continuous segments, plot their average duration, median duration per patient\n",
    "# correlate that with time to MAPopt calculation (the longer it takes to calculate, the more difficult they are to get out of disruption???)\n",
    "\n",
    "# loop through each patient's in and out and get the segments\n",
    "out_time = {}\n",
    "mode = 'mean'\n",
    "with h5py.File(global_path, \"r\") as f:\n",
    "    for pt in f:\n",
    "        if f[f\"{pt}/processed/in_out_{mode}\"].attrs[\"no_label_overlap\"]:\n",
    "            continue\n",
    "        out_df = ~(pd.Series(f[f\"{pt}/processed/in_out_{mode}/in_out\"][...], name = \"out?\").astype(bool))\n",
    "        timestamp = pd.Series(f[f\"{pt}/processed/in_out_{mode}/label_timestamp\"][...], name = \"timestamp\")\n",
    "        combined = pd.concat([out_df, timestamp], axis=1)\n",
    "        combined = combined.set_index('timestamp', drop=True)\n",
    "\n",
    "        # consider that some of these will be N/A, print them\n",
    "        # print(\"NAs:\", combined[\"out?\"].isna().sum())\n",
    "\n",
    "        signal = combined['out?']\n",
    "        change = signal.ne(signal.shift()).cumsum()\n",
    "        true_groups = (\n",
    "            combined.groupby(change)\n",
    "            .filter(lambda g: g['out?'].iloc[0]) # keep only True outs\n",
    "            .groupby(change)\n",
    "        )\n",
    "        intervals = true_groups.apply(\n",
    "            lambda g: pd.Series({\n",
    "                'start': pd.to_datetime(get_start_time(g, combined.index), unit='us'),\n",
    "                'end': pd.to_datetime(g.index[-1], unit='us'),\n",
    "                'duration': g.index[-1] - get_start_time(g, combined.index)\n",
    "            })\n",
    "        )\n",
    "\n",
    "        out_time[pt] = intervals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b34e407",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.DataFrame([(pt, val) for pt, vals in out_time.items() for val in vals['duration']], columns = ['ptid', 'duration'])\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08590f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9890b1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# violin plots\n",
    "combined_df_min = combined_df.assign(duration=combined_df['duration'] / (1e6*60))\n",
    "filtered = combined_df_min[(combined_df_min['duration'] < 20)*(combined_df_min['duration'] > 1)]\n",
    "with plt.rc_context({'xtick.bottom': False}):\n",
    "        fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(20,14), layout='constrained')\n",
    "        sns.boxplot(data = combined_df_min, x='ptid', y='duration', ax=ax1, dodge=True, fliersize=0)\n",
    "        sns.boxplot(data = filtered, x='ptid', y='duration', ax=ax2, dodge=True, fliersize=0)\n",
    "\n",
    "        ax1.set_ylabel('Duration (minutes)')\n",
    "        ax2.set_ylabel('Duration (minutes)')\n",
    "        ax1.set_xlabel('')\n",
    "        ax2.set_xlabel('Recordings')\n",
    "        ax1.set_ylim(0, 500)\n",
    "        ax1.xaxis.set_ticklabels([])\n",
    "        ax2.xaxis.set_ticklabels([])\n",
    "\n",
    "        fig.suptitle('Boxplots of Outside Autoregulation Segments Durations')\n",
    "        ax1.set_title(f\"All Recordings (n = {combined_df_min.shape[0]} segments over {combined_df_min['ptid'].unique().shape[0]} patients)\")\n",
    "        ax2.set_title(f\"Recordings with length between 2 and 20 minutes\\n(n = {filtered.shape[0]} segments over {filtered['ptid'].unique().shape[0]} patients)\")\n",
    "\n",
    "        img_name = f\"out_seg_dur_per_patient.png\"\n",
    "        plt.savefig(os.path.join(img_dir, img_name), bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151f36fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can use groupby\n",
    "with h5py.File(global_path, \"r\") as f:\n",
    "        summary_df = combined_df.groupby('ptid').apply(\n",
    "            lambda x: pd.Series({\n",
    "                'num_seg': x['duration'].shape[0],\n",
    "                'mean': x['duration'].mean(),\n",
    "                'median': x['duration'].median(),\n",
    "                'stddev': x['duration'].std(),\n",
    "                'max': x['duration'].max(),\n",
    "                'min': x['duration'].min(),\n",
    "                'freq_perhr': (x['duration'].shape[0] / float(f[f\"{x.name}/raw\"].attrs['duration'][0].removesuffix(' seconds'))) * 60 * 60\n",
    "            }), include_groups=False\n",
    "        )\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab150a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add % time in out and total length of recording to summary df and time to MAPopt calc\n",
    "with h5py.File(global_path, \"r\") as f:\n",
    "    summary_df[\"total_recording_s\"] = summary_df.index.map(\n",
    "        lambda x: (int(f[f\"{x}/raw\"].attrs['dataEndTimeUnix'][0]) - int(f[f\"{x}/raw\"].attrs['dataStartTimeUnix'][0]))\n",
    "    )\n",
    "summary_df[\"percent_out\"] = timevpercent[\"out_percent\"]\n",
    "summary_df['to_first_MAPopt_s'] = elapsed_times_idx\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5f1e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8116cb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = summary_df[summary_df['to_first_MAPopt_s'] < 300_000]\n",
    "summary_df = summary_df[summary_df['total_recording_s'] < 7_000_000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1556bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b125a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df_min = summary_df.assign(\n",
    "    **summary_df[['mean', 'median', 'stddev', 'max', 'min']].transform(lambda x: x / (1e6*60))\n",
    ")\n",
    "summary_df_min = (\n",
    "    summary_df_min.drop(columns=['to_first_MAPopt_s', 'total_recording_s'])\n",
    "    .assign(\n",
    "        **summary_df[['to_first_MAPopt_s', 'total_recording_s']]\n",
    "          .transform(lambda x: x / 60)\n",
    "          .rename(columns=lambda c: re.sub(r'_s$', '_min', c))\n",
    "    )\n",
    ")\n",
    "summary_df_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec021ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of rows/cols for subplots\n",
    "nrows = int(np.sqrt(len(summary_df_min.columns)))\n",
    "ncols = len(summary_df_min.columns) // nrows + (len(summary_df_min.columns) % nrows) % nrows\n",
    "\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, layout='constrained', figsize=(8*ncols, 6*nrows))\n",
    "\n",
    "for i, stat in enumerate(summary_df_min.columns):\n",
    "    ax = axes[i//ncols, i%ncols]\n",
    "    sns.violinplot(\n",
    "        data=summary_df_min[stat],\n",
    "        ax=ax,\n",
    "        inner=\"box\",\n",
    "        cut=0,\n",
    "    )\n",
    "    ax.set_title(f\"{stat.capitalize()}\")\n",
    "    ax.tick_params(axis=\"x\", rotation=90)\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"\")\n",
    "\n",
    "    mean_value = summary_df_min[stat].mean()\n",
    "    ax.axhline(y=mean_value, color='red', linestyle='--', label=f'Mean: {mean_value:.2f}')\n",
    "    ax.legend()\n",
    "\n",
    "# hide any unused subplots\n",
    "for i, a in enumerate(axes.flat):\n",
    "    if i > len(summary_df_min.columns) - 1:\n",
    "        a.set_axis_off()\n",
    "\n",
    "fig.suptitle(f\"Violin plots of summary statistics of duration per window (min)\")\n",
    "\n",
    "img_name = \"segments_summary_stats.png\"\n",
    "plt.savefig(os.path.join(img_dir, img_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516714e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then min-max scale all of these\n",
    "from sklearn.preprocessing import MinMaxScaler, PowerTransformer\n",
    "scaler = MinMaxScaler()\n",
    "scaler_box = PowerTransformer(method='box-cox')\n",
    "scaled_values = scaler.fit_transform(summary_df)\n",
    "summary_df_scaled = pd.DataFrame(scaled_values, columns=summary_df.columns)\n",
    "summary_df_scaled.describe().T\n",
    "# then do correlation plot for all of these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fabb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = summary_df_scaled.columns\n",
    "corr = summary_df_scaled.corr()\n",
    "pvals = pd.DataFrame(np.ones_like(corr), columns=cols, index=cols)\n",
    "\n",
    "\n",
    "for i in cols:\n",
    "    for j in cols:\n",
    "        r, p = pearsonr(summary_df_scaled[i], summary_df_scaled[j])\n",
    "        pvals.loc[i, j] = p\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5571b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix\n",
    "with sns.axes_style(\"white\"):\n",
    "    annot = corr.round(2).astype(str) + \"\\n(p=\" + pvals.round(3).astype(str) + \")\"\n",
    "    mask = (pvals > 0.05) | (pvals.isna())\n",
    "\n",
    "    plt.figure(figsize=(14, 12))\n",
    "    sns.heatmap(corr, mask=mask, annot=annot, cmap=\"coolwarm\", vmin=-1, vmax=1, square=True, cbar=False, fmt=\"\", cbar_kws={\"label\": \"Pearson r\"}, annot_kws={\"size\": 12})\n",
    "    plt.title(\"Correlation Matrix of Summary Stats\")\n",
    "    plt.tight_layout()\n",
    "    img_name = \"heatmap.png\"\n",
    "    plt.savefig(os.path.join(img_dir, img_name))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b1ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(8, 6))\n",
    "dict_to_show = {'x': summary_df_scaled.columns.drop([\"min\", \"total_recording_s\"]), 'y': ['num_seg', 'freq_perhr', 'percent_out', 'to_first_MAPopt_s']}\n",
    "sns.pairplot(summary_df_scaled, \n",
    "    diag_kind='hist', \n",
    "    corner=True, \n",
    "    dropna=True)\n",
    "plt.suptitle(\"Pairwise Relationships Between Summary Stats\", y=1.02)\n",
    "img_name = \"pairplot.png\"\n",
    "plt.savefig(os.path.join(img_dir, img_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48e3ce9",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77be616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0018a4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1589' '702' '1453' '1178' '1447' '208' '1511' '294' '1013' '205' '646'\n",
      " '1034' '986' '1491' '777' '647' '336' '1747' '2142' '634' '1210' '642'\n",
      " '1224' '640' '2011' '1910' '216' '1500' '1551' '597_3' '1130' '1002'\n",
      " '1479' '1555' '203' '258' '597_2' '598' '238' '259' '623' '281' '617'\n",
      " '1198' '1539' '1518' '754' '1991' '212' '214' '743' '614' '1033' '1865'\n",
      " '318' '657' '204' '2041' '1496' '595' '654' '787' '1708' '923' '324'\n",
      " '331' '1061' '775' '233' '284' '722' '255' '779' '222' '637' '1148' '330'\n",
      " '342' '200' '2004' '1046' '2106' '972' '679' '1661' '1640' '1012' '1872'\n",
      " '618' '1586' '1549' '1090' '1632' '1996' '2124' '1765' '1102' '1505'\n",
      " '271' '1219' '1184' '734' '769' '234' '1120' '315' '1055' '1126' '1532'\n",
      " '690_3' '1497' '1122' '1912' '771' '969' '1472' '1063' '615' '251' '1174'\n",
      " '958' '1048' '1840' '688' '993' '635' '1755' '728' '594' '596' '763'\n",
      " '645' '1203' '206' '1004' '1969' '211' '1471' '1009' '290' '1659' '239'\n",
      " '1144_2' '201' '2135' '916' '291' '310' '341' '285' '2107' '1630' '651'\n",
      " '770' '1660' '937' '1066' '1077' '333' '1185' '605' '921' '322' '1101'\n",
      " '338' '1455' '929' '966' '1976' '1977' '1515' '710' '700' '1762' '1723'\n",
      " '1617' '282' '1190' '677' '1215' '928' '325' '661' '606' '1649' '1597']\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(global_path, \"r\") as f:\n",
    "    print(np.array(f['healthy_ptids'][...]).astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aafb7e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make combined info df\n",
    "information = []\n",
    "mode = 'mean'\n",
    "with h5py.File(global_path, \"r\") as f:\n",
    "    for pt in np.array(f['healthy_ptids'][...]).astype(str):\n",
    "        in_out_df = pd.Series(f[f\"{pt}/processed/in_out_{mode}/in_out\"][...]).astype(bool)\n",
    "        idx_window = pd.DataFrame(f[f\"{pt}/processed/in_out_{mode}/window_idx\"][...])\n",
    "        tmp = pd.concat([in_out_df, idx_window], axis=1)\n",
    "        tmp.columns = ['in?', 'startidx', 'endidx']\n",
    "        tmp['ptid'] = pt\n",
    "        information.append(tmp)\n",
    "info_df = pd.concat(information).reset_index(drop=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bb03108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if windows have unequal length (they should not)\n",
    "info_df['len'] = info_df['endidx'] - info_df['startidx']\n",
    "assert len(info_df['len'].unique()) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92eef0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_arr_path = '/home/mr2238/project_pi_np442/mr2238/accelerate/data/processed/big_array.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88689642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving all windows into a numpy memmap file\n",
    "windows = np.memmap(big_arr_path, dtype='float32', mode='w+', shape=[info_df.shape[0], info_df['len'][0] + 1])\n",
    "with h5py.File(global_path, \"r\") as f:\n",
    "    uniques = info_df.ptid.unique()\n",
    "    for pt in tqdm(uniques):\n",
    "        abp_arr = f[f\"{pt}/raw/waves/abp\"]\n",
    "        ptid_info = info_df[info_df['ptid'] == pt]\n",
    "        for w, row in ptid_info.iterrows():\n",
    "            abp_arr.read_direct(windows, source_sel=np.s_[row['startidx']: row['endidx']], dest_sel=np.s_[w, 1:])\n",
    "            windows[w, 0] = w\n",
    "        print(windows[w, :])\n",
    "\n",
    "windows.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c993a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e9467b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load as a numpy array (if memory is enough)\n",
    "windows = da.from_array(np.memmap(big_arr_path, dtype='float32', mode='r', shape=(info_df.shape[0], info_df['len'][0] + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdb3f3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 7.01 GiB </td>\n",
       "                        <td> 127.97 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (251016, 7501) </td>\n",
       "                        <td> (5792, 5792) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 88 chunks in 2 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> float32 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"81\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"31\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"5\" x2=\"31\" y2=\"5\" />\n",
       "  <line x1=\"0\" y1=\"11\" x2=\"31\" y2=\"11\" />\n",
       "  <line x1=\"0\" y1=\"16\" x2=\"31\" y2=\"16\" />\n",
       "  <line x1=\"0\" y1=\"24\" x2=\"31\" y2=\"24\" />\n",
       "  <line x1=\"0\" y1=\"30\" x2=\"31\" y2=\"30\" />\n",
       "  <line x1=\"0\" y1=\"35\" x2=\"31\" y2=\"35\" />\n",
       "  <line x1=\"0\" y1=\"44\" x2=\"31\" y2=\"44\" />\n",
       "  <line x1=\"0\" y1=\"49\" x2=\"31\" y2=\"49\" />\n",
       "  <line x1=\"0\" y1=\"55\" x2=\"31\" y2=\"55\" />\n",
       "  <line x1=\"0\" y1=\"63\" x2=\"31\" y2=\"63\" />\n",
       "  <line x1=\"0\" y1=\"69\" x2=\"31\" y2=\"69\" />\n",
       "  <line x1=\"0\" y1=\"74\" x2=\"31\" y2=\"74\" />\n",
       "  <line x1=\"0\" y1=\"83\" x2=\"31\" y2=\"83\" />\n",
       "  <line x1=\"0\" y1=\"88\" x2=\"31\" y2=\"88\" />\n",
       "  <line x1=\"0\" y1=\"94\" x2=\"31\" y2=\"94\" />\n",
       "  <line x1=\"0\" y1=\"102\" x2=\"31\" y2=\"102\" />\n",
       "  <line x1=\"0\" y1=\"107\" x2=\"31\" y2=\"107\" />\n",
       "  <line x1=\"0\" y1=\"113\" x2=\"31\" y2=\"113\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"31\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"24\" y1=\"0\" x2=\"24\" y2=\"120\" />\n",
       "  <line x1=\"31\" y1=\"0\" x2=\"31\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 31.366908166088546,0.0 31.366908166088546,120.0 0.0,120.0\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"15.683454\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >7501</text>\n",
       "  <text x=\"51.366908\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,51.366908,60.000000)\">251016</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<array, shape=(251016, 7501), dtype=float32, chunksize=(5792, 5792), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "587608be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will need to replace invalid values with median of window\n",
    "with h5py.File(global_path, \"r\") as f:\n",
    "    nan_value = f.attrs[\"invalid_val\"]\n",
    "\n",
    "windows[windows == nan_value] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63c619d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>251,016.00</td>\n",
       "      <td>227,709.00</td>\n",
       "      <td>227,713.00</td>\n",
       "      <td>227,710.00</td>\n",
       "      <td>227,710.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>125,507.51</td>\n",
       "      <td>88.39</td>\n",
       "      <td>88.39</td>\n",
       "      <td>88.39</td>\n",
       "      <td>88.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>72,462.22</td>\n",
       "      <td>38.67</td>\n",
       "      <td>38.68</td>\n",
       "      <td>38.68</td>\n",
       "      <td>38.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-50.01</td>\n",
       "      <td>-50.01</td>\n",
       "      <td>-50.01</td>\n",
       "      <td>-50.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>62,263.25</td>\n",
       "      <td>74.60</td>\n",
       "      <td>74.46</td>\n",
       "      <td>74.41</td>\n",
       "      <td>74.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>124,527.50</td>\n",
       "      <td>95.61</td>\n",
       "      <td>95.69</td>\n",
       "      <td>95.85</td>\n",
       "      <td>95.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>188,239.50</td>\n",
       "      <td>129.93</td>\n",
       "      <td>130.16</td>\n",
       "      <td>130.09</td>\n",
       "      <td>130.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>251,015.00</td>\n",
       "      <td>299.87</td>\n",
       "      <td>299.87</td>\n",
       "      <td>299.87</td>\n",
       "      <td>299.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0          1          2          3          4\n",
       "count 251,016.00 227,709.00 227,713.00 227,710.00 227,710.00\n",
       "mean  125,507.51      88.39      88.39      88.39      88.40\n",
       "std    72,462.22      38.67      38.68      38.68      38.69\n",
       "min         0.00     -50.01     -50.01     -50.01     -50.01\n",
       "25%    62,263.25      74.60      74.46      74.41      74.55\n",
       "50%   124,527.50      95.61      95.69      95.85      95.67\n",
       "75%   188,239.50     129.93     130.16     130.09     130.81\n",
       "max   251,015.00     299.87     299.87     299.87     299.87"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.from_dask_array(windows[:, :5]).describe().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643f62a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ba1591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_values = scaler.fit_transform(windows[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb79e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do umap\n",
    "fit = umap.UMAP()\n",
    "u = fit.fit_transform(windows[:, 1:])\n",
    "u_df = pd.DataFrame(u, columns = ['dim_1', 'dim_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295dda74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do umap on padded windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef64125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph and color by in or out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8576719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative: do PCA, select dims that cover >90% of var, and then UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdd91a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: train/test split (in separate script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a14548",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d35eb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b95faeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
